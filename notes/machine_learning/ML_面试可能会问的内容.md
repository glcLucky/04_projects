# **周志华机器学习笔记**

[TOC]

# 一. 模型评估与选择
----

## 1. 机器学习的含义 
假设用P来评估计算机程序在某任务类T上的性能，若一个程序通过利用经验E在T中任务上获得性能的改善，则我们就说关于T和P，该程序对E进行了学习

## 2. 奥卡姆剃刀定律：若有多个假设与观察一致，则选择最简单的哪个。

## 3. NFL定理(No Free Lunch)
- [含义] 总误差与学习算法无关，是一个常数，即无论算法A多么聪明，算法B多么笨拙，他们的期望性能相同。

- [前提] 所有"问题"出现的机会相同或所有问题同等重要。

- [启示] 脱离具体问题，空谈"什么算法更好"毫无意义，因为**若考虑所有潜在的问题，则所有算法都一样好**。此时归纳偏好往往起决定作用

## 4.模型评估方法

### 4.1 留出法 (hold-out)
- [含义] 直接将D通过分层抽样划分为两个互斥的集合，其中一个作为训练集S，另一个作为测试集T

- [注意问题] 多次划分取平均

- [评价] 选择T和S的size存在争议 通常将2/3-4/5的样本用于训练


### 4.2 交叉验证 (cross validation)
- [含义] p次k折交叉验证: 将数据集D通过分层抽样的方法划分为k个互斥子集，将其中k-1个子集作为训练集，余下的一个作为测试集进行测试，样可以进行k次训练和测试，由于划分k个子集的方法有多种，这里重复p次，则一共可进行p次k折交叉验证，将每次评估结果进行平均。

- [特殊情况] 当k=m时，称为'留一法' 即m个样本只有唯一的方式划分为m个子集，每个子集只包含一个样本。 留一法的结果往往比较准确，但开销很大。

- [缺点] 因为保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比D小，这必然会引入一些因训练样本规模不同而导致的估计偏差。


### 4.3 自助法(bootstrap)
- [含义] 有放回抽样m次得到m个样本，大约有36.8%的数据没被抽中，因此这些数据可用来测试，亦称"包外估计"

- [优点] 在数据集较小、难以有效划分训练/测试集时很有用，此外自助法能够从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。

- [缺点] 自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差，因此，在初始数据量足够时，留出法和交叉法更常用一些。

## 4.性能度量方法，

### 4.1 基本方法
对于分类任务通常用准确率(精度),即预测正确的样本占总样本的比重。
对于回归任务通常用均方误差。

### 4.2 查全率R和查准率F
- 查全率R = TP/(TP+FN) 表示好瓜有多少被挑出来。
- 查准率P = TP/(TP+FP) 表示挑出的瓜中有多少是真正的好瓜
- F1 R和P的调和平均数 调和平均数相对数算数平均数和几何平均数而言更加重视较小值。
- Fβ R和P的加权调和平均数 β大于1查全率影响更大 反之查准率影响更大。

### 4.3 ROC与AUC
- 适用情况: 能够产生实值或概率预测的学习器
- 背景
根据概率预测结果将样本降序排列，则越排在前面的越有可能是正例，不同的任务选择不同的阈值，比如更重视查全率，则可以选择较低的阈值，若更重视查准率则可以选择较高的阈值。**因此排序本身的质量好坏，体现了综合考虑学习器在不同任务下的"期望泛化性能"的好坏**，ROC曲线就是从这个角度出发研究学习器泛化性能的有力工具。

- ROC全称受试者工作特征曲线(Receiver Operating Characteristic)。

-绘制: 根据学习的预测结果对样本进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要的值FPR和TPR，分别作为横、纵坐标。
    TPR称为'真正例率'，TPR=TP/(TP+FN) 等价于查全率 即好瓜有多少被挑出来 
    FPR称为'假正例率'，FPR=FP/(TN+FP) 即坏瓜有多少比例被预测为好瓜。

-[含义] ROC曲线上的每一点表示在某一阈值下TPR和FPR的趋势，显然越靠近(0,1)点，说明TPR越大，FPR越小，若一个学习器的ROC曲线完全包住了另一个学习器的ROC曲线，则说明前者在任何一个阈值下的预测性能都优于后者，显然前者优于后者。如果两条ROC曲线发生了交叉，则可以比较它们曲线下面积，即AUC值 

-[AUC] AUC值的ROC曲线下面积，它的本质是一个概率值，表示当前的学习器根据预测的概率值将正样本排在负样本前面的概率。


## 5.偏差方差分解
泛化误差 = 偏差(bias) + 方差(var) + 噪声(noise)

`噪声：干扰信号的偶然因素。比如实际y=4，但录入数据时将y录成了3.这种误差就是噪声，通常假设噪声的期望值为0`

-[bias] 偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力
-[var] 方差度量了**同样大小**的训练集的变动所导致学习性能的变化，即刻画了数据扰动所造成的影响
-[noise] 表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。

偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的，给定学习任务，为了取得好的泛化性能，则需使偏差较小，既能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。

一般来说，偏差与方差是有冲突的(bias-variance dilemma) 给定学习任务，假定我们能控制学习算法的训练程度，则在训练不足时，学习器拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时**偏差主导泛化错误率**，随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，**方差逐渐住主导了泛化错误率**，在训练程度充足时，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合。



# 二. 线性模型

----

基本形式 f(x) = $W^{T}$X + b

## 1. 线性回归 
-[cost function] MSE 均方误差

-[OLS] 最小二乘法: 基于MSE最小化来进行模型求解的方法称为最小二乘法，在线性回归中，OLS就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小

-[求解] 正规方程法 梯度下降法

## 2. 逻辑回归/对数几率回归
-[基本形式] 
    $$y=\frac{1}{1+e^{-(w^Tx+b)}}$$
- [link function] 将线性回归模型的预测值与真实标记连接起来的函数 逻辑回归的link函数为sigmoid函数
    $$y=\frac{1}{1+e^-z}$$

-[sigmoind函数的特点] 将实数(线性回归的结果)映射到0-1之间，在z=0附近变化很陡峭，是任意阶可导凸函数。是单位阶跃函数比较好的替代。

-[估计方法] MLE

-[求解方法] 梯度下降法 牛顿迭代法均可以

## 3. 线性判别分析(LDA) 
-[思想] 给定训练集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能近，异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置确定新样本的类别。


## 4. 多分类学习的处理
多分类学习主要有三种处理方法 OvO OvR MvM
-[OvO] 一对一 即将N个类别两两匹配进行训练，可以得到N(N-1)/2个分类结果，然后通过投票产生，即把被预测得最多的类别作为最终分类结果。

-[OvR] 一对多 每次将一个类的样例作为正例，其余作为反例，进行训练，则可训练出N个分类器，**在测试时如果仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果。若有多个分类器预测为正类，则通常需要考虑分类器的预测置信度，选择置信度最大的类别标记作为分类结果。**

OvO与OvR效果通常差不多


## 5. 类别不平衡问题 class-imbalance
-[含义] 类别不平衡是指分类任务中不同类别的训练样例数目差别很大。

解决方案

-[欠采样] 去除一些类别较多的以保证不同类别数目接近，然后再进行学习。开销较小，但若随机丢弃，可能丢失一些重要信息。代表性算法是EasyEnsemble
-[过采样] 增加一些样例较少的类别。开销较大，不能简单地对不足样例的类别进行重采样，否则会导致严重的过拟合，代表算法是SMOTE
-[阈值移动] 又叫再缩放，适用于根据阈值预测类别的学习器，如逻辑回归，通过调整阈值的方法来解决。
    正常阈值:$$\frac{y}{1-y} > 1$$时 预测为正例 等价于y>0.5 时取1
    阈值调整:$$\frac{y}{1-y}\times\frac{m^-}{m^+}>1$$ 时预测为正例

# 三. 决策树模型

----
## 1. 含义
决策树是一种可用于分类和回归任务的非参监督学习算法，目标在于通过从数据特征中学习一些简单的决策规则来创建一个预测目标值的模型。
具体而言，一颗决策树包含一个根结点、若干个内部结点和若干个叶结点；叶结点对应于决策结果，其他每个结点对应于一个属性测试，每个结点包含的样本集合根据属性测试的结果被划分到子结点中，根结点包含样本全集，从根结点到每个叶节点的路径对应了一个判定测试序列。决策树学习的目的是为了产生一颗泛化能力强的树。

## 2. 优点
- 简单且易于解释，树能够被可视化。
- 要求较少的数据准备工作，其他技术经常要去数据服从正态分布。决策树不允许有缺失值。
- 用决策树的成本是用于训练的数据点个数的对数级
- 能够处理数值型和分类型变量。
- 能够处理多分类问题。
- 决策树是白箱模型，对于特定的预测结果，可以通过对各节点的属性测试序列来解释，且越往上的叶子对应的属性，其对结果的贡献越大，因为我们每层都是选择最优划分属性。相比之下，黑箱模型的结果难以解释。
- 可以使用统计检验的方法来验证模型，这有助于解释模型的可靠性

## 2. 缺点
- 容易产生过拟合，可以通过剪枝、在叶子节点设定最小样本量以及设定最大深度来缓解过拟合的问题。
- 决策树算法不太稳定。在数据集较小的变动可能会导致差异很大的树。
- 决策树问题的求解通常是NP难问题，因此决策树算法求解通常基于启发式算法，例如贪心算法，它在选择划分属性时往往是基于当前结点最优(局部最优),并不能保证在这个树上是最优的(全局最优),这可以通过集成学习的方法来缓解。
- 无法处理一些概念，比如异或问题
- 如果数据集中类别严重不平衡，决策树可能有偏，因此建议在拟合之前先平衡数据集。

## 3. 导致递归返回的三种情形:(产生叶节点)
- 当前节点包含的样本全属于同一类，无需划分。将当前节点标记为叶节点，其类别为该类别。
- 当前属性集为空，或者当前所有样本在当前所有属性上取值相同，无法划分。将当前节点标记为叶节点，其类别为该节点所含样本最多的类别。
- 当前节点包含的样本集合为空，不能划分。将当前节点标记为叶节点，其类别为其父节点所含样本最多的类别。

## 4. 划分选择的方法。
- 信息增基:
- 信息率：C4.5
- 基尼指数：CART

## 5. 连续值的处理方法
二分法: 给定样本集D和连续属性a，假定a在D上出现了n个不同的取值，将这些值从小到大排序，记为{$a^1,a^2,...,a^n$}
基于划分点t可将D划分为两个子集。

## 6. 缺失值的处理
两大问题
-[1] 如何在属性值缺失的情况下进行划分属性选择？
    设定一个样本权重$w_x$ 初始阶段，各样本权重设为1，以属性a为例，定义如下几个比例：
    $\rho$:该属性无缺失值样本所占比例
    $p_k$:无缺失值样本中第k类所占比例
    $r_v$:无缺失样本中在属性a上取值为$a^v$的样本所占的比例
-[2] 给定最佳划分属性，若样本在该属性上缺失，如何对样本进行划分？
将该样本同时划分给所有的子节点，同时基于属性a在不同取值的比例调整样本权值，即**让同一个样本以不同的概率划入到不同的子节点中取**