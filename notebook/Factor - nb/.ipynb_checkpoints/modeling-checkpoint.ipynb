{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import devkit.api as dk\n",
    "import finkit.api as fk\n",
    "import Factor.api as factor\n",
    "import ModelAPI.api as model\n",
    "import alpha.api as alpha\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model  # 线性模型\n",
    "from sklearn.svm import SVC  # 导入支持向量机分类器\n",
    "from sklearn import tree  # 导入决策树分类器\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV  # 导入网格搜索便于调试找到最优参数\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factor.get_secs_multiple_index_stds??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trading_days = fk.get_trading_days('2005-01-01', '2014-01-01')\n",
    "trading_days = sorted(trading_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单因子有效性检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单因子累计收益图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2018-04-21 10:06:38 index_std is connected.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "conn = dk.MySQLProxy()\n",
    "conn.connect('root', '123888', 'index_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2018-04-21 10:28:59 index_std is connected.\u001b[0m\n",
      "\u001b[34m[INFO] 2018-04-21 10:28:59 SELECT table_name FROM information_schema.tables WHERE table_schema = 'index_std'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "index_stds = dk.get_tables_on_given_database('root', '123888', 'index_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index_std in index_stds:\n",
    "    trading_days = conn.query_as_dataframe(\"SELECT DISTINCT date FROM {}\".format(index_std))\n",
    "    trading_days = trading_days.date.tolist()\n",
    "    factor.get_single_index_daily_return(index_std,trading_days, 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单因子检验的p值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 从指定文件夹读入所有因子日度收益\n",
    "- 对各因子进行配对t检验 获得检验的p值存入字典中\n",
    "- 基于中位数对数据进行中心化 剔除p值大于中位数的index，然后对小于中位数的部分计算权重 \n",
    "- 计算各index的权重 权重计算方式: 中心化p值.sum() / 中心化p值 p值越小 权重越大\n",
    "- 将数据存入字典当中 并输出到外部json文件 key: index值 value: {\"p_value\", \"p_value_center\",\"weight\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cycle = 400\n",
    "path = r\"E:\\07_data\\02_factor\\daily_return\"\n",
    "date_initial = trading_days[cycle]\n",
    "a=factor.get_ttest_result_for_index_std_on_given_folder(trading_days[1000],trading_days[1401] ,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windows = 200  # 计算因子权重的窗口期\n",
    "p_threshhold = 0.1  # 仅选取p_value < 0.1 的因子 等权重\n",
    "path = r\"E:\\07_data\\02_factor\\daily_return\"\n",
    "date_initial = trading_days[cycle]\n",
    "for i in range(len(trading_days)):\n",
    "    if i < cycle:\n",
    "        continue\n",
    "    a=factor.get_ttest_result_for_index_std_on_given_folder(trading_days[i-windows],trading_days[i] ,path)\n",
    "    b=pd.DataFrame(a).T\n",
    "    c=b[b.pvalue < 0.1]\n",
    "    d = c.sort_values(['pvalue'])\n",
    "    d['weight'] = 1 / len(d)\n",
    "\n",
    "    e = d.T.to_dict()\n",
    "    dk.dict2json(e, r\"E:\\07_data\\02_factor\\factor_weight\\cycle200\\{}.json\".format(trading_days[i]))\n",
    "    del a, b, c, d, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于打分的传统多因子选股模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-06\n",
      "2015-02-25\n",
      "2015-04-10\n",
      "2015-05-26\n",
      "2015-07-09\n",
      "2015-08-21\n",
      "2015-10-14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_300_return</th>\n",
       "      <th>model_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>-0.032611</td>\n",
       "      <td>0.074152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-25</th>\n",
       "      <td>0.192589</td>\n",
       "      <td>0.564892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-10</th>\n",
       "      <td>0.366394</td>\n",
       "      <td>0.804733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-26</th>\n",
       "      <td>0.070971</td>\n",
       "      <td>0.543372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-09</th>\n",
       "      <td>0.036033</td>\n",
       "      <td>0.533342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-21</th>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.478709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-14</th>\n",
       "      <td>0.106021</td>\n",
       "      <td>0.795720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hs_300_return  model_return\n",
       "2015-01-06      -0.032611      0.074152\n",
       "2015-02-25       0.192589      0.564892\n",
       "2015-04-10       0.366394      0.804733\n",
       "2015-05-26       0.070971      0.543372\n",
       "2015-07-09       0.036033      0.533342\n",
       "2015-08-21      -0.004220      0.478709\n",
       "2015-10-14       0.106021      0.795720"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=alpha.back_test_on_given_model(\"2015-01-06\", \"2015-12-31\", 30, 200, 20, alpha.mfs_by_score)\n",
    "b=pd.DataFrame(a).T\n",
    "b.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于LR的选股模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-06\n",
      "2015-02-25\n",
      "2015-04-10\n",
      "2015-05-26\n",
      "2015-07-09\n",
      "2015-08-21\n",
      "2015-10-14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_300_return</th>\n",
       "      <th>model_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>-0.032611</td>\n",
       "      <td>0.028365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-25</th>\n",
       "      <td>0.192589</td>\n",
       "      <td>0.351268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-10</th>\n",
       "      <td>0.366394</td>\n",
       "      <td>0.658539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-26</th>\n",
       "      <td>0.070971</td>\n",
       "      <td>0.087959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-09</th>\n",
       "      <td>0.036033</td>\n",
       "      <td>0.369922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-21</th>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.395097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-14</th>\n",
       "      <td>0.106021</td>\n",
       "      <td>0.653632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hs_300_return  model_return\n",
       "2015-01-06      -0.032611      0.028365\n",
       "2015-02-25       0.192589      0.351268\n",
       "2015-04-10       0.366394      0.658539\n",
       "2015-05-26       0.070971      0.087959\n",
       "2015-07-09       0.036033      0.369922\n",
       "2015-08-21      -0.004220      0.395097\n",
       "2015-10-14       0.106021      0.653632"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "features = ['boll_15_std', 'boll_30_std', 'boll_45_std', 'boll_60_std', 'boll_100_std']\n",
    "lr_model = partial(alpha.mfs_by_LR, num2=20, cycle=20, windows_step2=30, features=features)\n",
    "c=alpha.back_test_on_given_model(start_date=\"2015-01-06\", end_date=\"2015-12-31\", cycle=30, windows=200, num=1000, model=lr_model)\n",
    "d=pd.DataFrame(c).T\n",
    "d.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于SVC的选股模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-06\n",
      "2015-02-25\n",
      "2015-04-10\n",
      "2015-05-26\n",
      "2015-07-09\n",
      "2015-08-21\n",
      "2015-10-14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_300_return</th>\n",
       "      <th>model_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>-0.032611</td>\n",
       "      <td>0.228947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-25</th>\n",
       "      <td>0.192589</td>\n",
       "      <td>0.532505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-10</th>\n",
       "      <td>0.366394</td>\n",
       "      <td>0.899642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-26</th>\n",
       "      <td>0.070971</td>\n",
       "      <td>0.431462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-09</th>\n",
       "      <td>0.036033</td>\n",
       "      <td>0.576473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-21</th>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.537793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-14</th>\n",
       "      <td>0.106021</td>\n",
       "      <td>0.656407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hs_300_return  model_return\n",
       "2015-01-06      -0.032611      0.228947\n",
       "2015-02-25       0.192589      0.532505\n",
       "2015-04-10       0.366394      0.899642\n",
       "2015-05-26       0.070971      0.431462\n",
       "2015-07-09       0.036033      0.576473\n",
       "2015-08-21      -0.004220      0.537793\n",
       "2015-10-14       0.106021      0.656407"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "features = ['boll_15_std', 'boll_30_std', 'boll_45_std', 'boll_60_std', 'boll_100_std']\n",
    "params={'kernel': 'rbf', 'probability': True, 'C': 1000}\n",
    "svc_model = partial(alpha.mfs_by_SVC, num2=20, cycle=20, windows_step2=30, features=features, params=params)\n",
    "e=alpha.back_test_on_given_model(start_date=\"2015-01-06\", end_date=\"2015-12-31\", cycle=30, windows=200, num=500, model=svc_model)\n",
    "f=pd.DataFrame(e).T\n",
    "f.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = dk.winsorize(a, 'future_ret', 0.01, 0.99)[\"normal_sector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mid = b.future_ret.quantile(0.5)\n",
    "for i in b.index:\n",
    "    if b.loc[i, 'future_ret'] > mid:\n",
    "        b.loc[i, 'good_stock'] = 1\n",
    "    else:\n",
    "        b.loc[i, 'good_stock'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del b['date']\n",
    "del b['future_ret']\n",
    "b = b.set_index(['sec_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = b.iloc[:, :-1]\n",
    "y = b.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={'kernel': 'rbf', 'probability': True, 'C': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = model.fit_SVC(X, y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69255768605784851"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69909218,  0.30090782],\n",
       "       [ 0.61725104,  0.38274896],\n",
       "       [ 0.64982561,  0.35017439],\n",
       "       ..., \n",
       "       [ 0.46806941,  0.53193059],\n",
       "       [ 0.44391845,  0.55608155],\n",
       "       [ 0.39004771,  0.60995229]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_SVC??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = model.fit_LR(b.iloc[:, :-1], b.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57491062723431918"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.score(b.iloc[:, :-1], b.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = a.sort_values(['future_ret'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.to_csv(r\"E:\\99_daily\\TODAY\\formal_db\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4459586466165413"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.betweena['future_ret'].quantile(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_300_return</th>\n",
       "      <th>model_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>-0.062918</td>\n",
       "      <td>0.189986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-11</th>\n",
       "      <td>-0.050943</td>\n",
       "      <td>0.219510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-12</th>\n",
       "      <td>-0.050751</td>\n",
       "      <td>0.349474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-09</th>\n",
       "      <td>0.070311</td>\n",
       "      <td>0.569534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-04</th>\n",
       "      <td>0.101606</td>\n",
       "      <td>0.567253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-10</th>\n",
       "      <td>0.521783</td>\n",
       "      <td>0.612630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>0.531219</td>\n",
       "      <td>0.713255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-13</th>\n",
       "      <td>0.843511</td>\n",
       "      <td>1.030389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-13</th>\n",
       "      <td>0.669553</td>\n",
       "      <td>0.720240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-10</th>\n",
       "      <td>0.481431</td>\n",
       "      <td>0.547762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-09</th>\n",
       "      <td>0.609204</td>\n",
       "      <td>1.047099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-12</th>\n",
       "      <td>0.494916</td>\n",
       "      <td>0.829746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>0.455210</td>\n",
       "      <td>0.746348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>0.460205</td>\n",
       "      <td>0.729950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-13</th>\n",
       "      <td>0.524677</td>\n",
       "      <td>0.946996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-13</th>\n",
       "      <td>0.542329</td>\n",
       "      <td>0.975922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-08</th>\n",
       "      <td>0.569483</td>\n",
       "      <td>1.055137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-15</th>\n",
       "      <td>0.541676</td>\n",
       "      <td>1.022654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-12</th>\n",
       "      <td>0.591074</td>\n",
       "      <td>1.030090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-17</th>\n",
       "      <td>0.580673</td>\n",
       "      <td>0.864839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-18</th>\n",
       "      <td>0.658788</td>\n",
       "      <td>0.720569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>0.705351</td>\n",
       "      <td>0.867263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-13</th>\n",
       "      <td>0.765483</td>\n",
       "      <td>0.823858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>0.794712</td>\n",
       "      <td>0.766845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-15</th>\n",
       "      <td>0.758977</td>\n",
       "      <td>0.745278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hs_300_return  model_return\n",
       "2014-01-06      -0.062918      0.189986\n",
       "2014-03-11      -0.050943      0.219510\n",
       "2014-05-12      -0.050751      0.349474\n",
       "2014-07-09       0.070311      0.569534\n",
       "2014-09-04       0.101606      0.567253\n",
       "2014-11-10       0.521783      0.612630\n",
       "2015-01-08       0.531219      0.713255\n",
       "2015-03-13       0.843511      1.030389\n",
       "2015-05-13       0.669553      0.720240\n",
       "2015-07-10       0.481431      0.547762\n",
       "2015-09-09       0.609204      1.047099\n",
       "2015-11-12       0.494916      0.829746\n",
       "2016-01-11       0.455210      0.746348\n",
       "2016-03-15       0.460205      0.729950\n",
       "2016-05-13       0.524677      0.946996\n",
       "2016-07-13       0.542329      0.975922\n",
       "2016-09-08       0.569483      1.055137\n",
       "2016-11-15       0.541676      1.022654\n",
       "2017-01-12       0.591074      1.030090\n",
       "2017-03-17       0.580673      0.864839\n",
       "2017-05-18       0.658788      0.720569\n",
       "2017-07-18       0.705351      0.867263\n",
       "2017-09-13       0.765483      0.823858\n",
       "2017-11-16       0.794712      0.766845\n",
       "2018-01-15       0.758977      0.745278"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=alpha.back_test_on_given_model(\"2014-01-06\", \"2018-03-31\", 40, 200, 20, lr_model)\n",
    "d=pd.DataFrame(c).T\n",
    "d.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-01-02\n",
      "2014-02-21\n",
      "2014-04-08\n",
      "2014-05-23\n",
      "2014-07-08\n",
      "2014-08-20\n",
      "2014-10-10\n",
      "2014-11-24\n",
      "2015-01-08\n",
      "2015-02-27\n",
      "2015-04-14\n",
      "2015-05-28\n",
      "2015-07-13\n",
      "2015-08-25\n",
      "2015-10-16\n",
      "2015-11-30\n",
      "2016-01-13\n",
      "2016-03-03\n",
      "2016-04-18\n",
      "2016-06-01\n",
      "2016-07-18\n",
      "2016-08-30\n",
      "2016-10-21\n",
      "2016-12-05\n",
      "2017-01-18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_300_return</th>\n",
       "      <th>model_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>-0.014876</td>\n",
       "      <td>0.059719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-21</th>\n",
       "      <td>-0.049687</td>\n",
       "      <td>0.070847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-08</th>\n",
       "      <td>-0.097265</td>\n",
       "      <td>-0.035111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-23</th>\n",
       "      <td>-0.084291</td>\n",
       "      <td>0.034881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-08</th>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.089411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-20</th>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.143967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-10</th>\n",
       "      <td>0.101058</td>\n",
       "      <td>0.134534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-24</th>\n",
       "      <td>0.476458</td>\n",
       "      <td>0.072156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>0.478435</td>\n",
       "      <td>0.066457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-27</th>\n",
       "      <td>0.715845</td>\n",
       "      <td>0.390990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-14</th>\n",
       "      <td>0.883312</td>\n",
       "      <td>0.699937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-28</th>\n",
       "      <td>0.732826</td>\n",
       "      <td>0.434047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-13</th>\n",
       "      <td>0.510528</td>\n",
       "      <td>0.270737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-25</th>\n",
       "      <td>0.656403</td>\n",
       "      <td>0.440821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-16</th>\n",
       "      <td>0.662891</td>\n",
       "      <td>0.516137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30</th>\n",
       "      <td>0.564556</td>\n",
       "      <td>0.477928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-13</th>\n",
       "      <td>0.531429</td>\n",
       "      <td>0.447049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-03</th>\n",
       "      <td>0.601329</td>\n",
       "      <td>0.613116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>0.583087</td>\n",
       "      <td>0.571474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01</th>\n",
       "      <td>0.619704</td>\n",
       "      <td>0.674722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-18</th>\n",
       "      <td>0.633732</td>\n",
       "      <td>0.688992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>0.635730</td>\n",
       "      <td>0.677581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-21</th>\n",
       "      <td>0.696196</td>\n",
       "      <td>0.698896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>0.654963</td>\n",
       "      <td>0.543442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-18</th>\n",
       "      <td>0.687714</td>\n",
       "      <td>0.619400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hs_300_return  model_return\n",
       "2014-01-02      -0.014876      0.059719\n",
       "2014-02-21      -0.049687      0.070847\n",
       "2014-04-08      -0.097265     -0.035111\n",
       "2014-05-23      -0.084291      0.034881\n",
       "2014-07-08       0.004816      0.089411\n",
       "2014-08-20       0.053763      0.143967\n",
       "2014-10-10       0.101058      0.134534\n",
       "2014-11-24       0.476458      0.072156\n",
       "2015-01-08       0.478435      0.066457\n",
       "2015-02-27       0.715845      0.390990\n",
       "2015-04-14       0.883312      0.699937\n",
       "2015-05-28       0.732826      0.434047\n",
       "2015-07-13       0.510528      0.270737\n",
       "2015-08-25       0.656403      0.440821\n",
       "2015-10-16       0.662891      0.516137\n",
       "2015-11-30       0.564556      0.477928\n",
       "2016-01-13       0.531429      0.447049\n",
       "2016-03-03       0.601329      0.613116\n",
       "2016-04-18       0.583087      0.571474\n",
       "2016-06-01       0.619704      0.674722\n",
       "2016-07-18       0.633732      0.688992\n",
       "2016-08-30       0.635730      0.677581\n",
       "2016-10-21       0.696196      0.698896\n",
       "2016-12-05       0.654963      0.543442\n",
       "2017-01-18       0.687714      0.619400"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=alpha.back_test_on_given_model(\"2014-01-02\", \"2017-03-31\", 30, 200, 20, lr_model)\n",
    "d=pd.DataFrame(c).T\n",
    "d.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=pd.DataFrame(c).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_300_return</th>\n",
       "      <th>model_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>0.017565</td>\n",
       "      <td>-0.002322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-10</th>\n",
       "      <td>-0.008746</td>\n",
       "      <td>-0.149085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-11</th>\n",
       "      <td>0.079747</td>\n",
       "      <td>-0.070680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-11</th>\n",
       "      <td>0.130482</td>\n",
       "      <td>-0.055464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-06</th>\n",
       "      <td>0.182062</td>\n",
       "      <td>-0.054695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>0.197482</td>\n",
       "      <td>-0.114037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>0.189672</td>\n",
       "      <td>-0.182955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hs_300_return  model_return\n",
       "2017-01-05       0.017565     -0.002322\n",
       "2017-03-10      -0.008746     -0.149085\n",
       "2017-05-11       0.079747     -0.070680\n",
       "2017-07-11       0.130482     -0.055464\n",
       "2017-09-06       0.182062     -0.054695\n",
       "2017-11-09       0.197482     -0.114037\n",
       "2018-01-08       0.189672     -0.182955"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = '2017-01-05'\n",
    "date_befort_cycle = \n",
    "seleted_stocks = alpha.mfs_by_score(date=date, windows=windows, num=num)\n",
    "train = factor.get_secs_multiple_index_stds(indes_stds, seleted_stocks, trading_days)\n",
    "\n",
    "close = factor.get_secs_index('close', seleted_stocks, fk.get_trading_days('2014-01-01', '2017-01-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trading_days = fk.get_trading_days('2010-01-01', '2010-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_stocks = alpha.mfs_by_score('2010-01-05', 200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close = factor.get_secs_index('close', selected_stocks, trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[INFO] 2018-05-13 12:58:19 以下股票由于盈利大于0.1被强制卖出: ['600008.SH']\u001b[0m\n",
      "\u001b[34m[INFO] 2018-05-13 12:58:19 以下股票由于盈利大于0.1被强制卖出: ['600201.SH']\u001b[0m\n",
      "\u001b[34m[INFO] 2018-05-13 12:58:19 以下股票由于亏损大于-0.1被强制卖出: ['600795.SH']\u001b[0m\n",
      "\u001b[34m[INFO] 2018-05-13 12:58:19 以下股票由于亏损大于-0.1被强制卖出: ['000966.SZ', '600396.SH', '600578.SH', '600743.SH', '600886.SH']\u001b[0m\n",
      "\u001b[34m[INFO] 2018-05-13 12:58:19 以下股票由于亏损大于-0.1被强制卖出: ['600010.SH']\u001b[0m\n",
      "\u001b[34m[INFO] 2018-05-13 12:58:19 以下股票由于盈利大于0.1被强制卖出: ['600620.SH']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trading_days = fk.get_trading_days('2015-01-01', '2015-12-31') # 回测区间\n",
    "def stop_loss_or_profit(sec_id, trading_days, stoploss, stopprofit, price_type='close'):\n",
    "    \"\"\"\n",
    "    在给定的有序交易日内第一天持仓给定股票 持有期间内 当损失或盈利大于阈值时卖出 到期间最后一天时 无论是否达到阈值 全部清仓\n",
    "    获得此种策略下的综合收益率\n",
    "    @sec_id <list>: 股票代码列表\n",
    "    @trading_days <list of str>: 回测区间\n",
    "    @stoploss <float>: 止损率 如=-0.1 即当浮亏率达到10%时卖出\n",
    "    @stopprofit <float>: 止盈率 如=0.1 即当浮盈率达到10%时卖出\n",
    "    @price_type <str>: 使用的价格类型 默认为收盘价\n",
    "    \"\"\"\n",
    "\n",
    "selected_stocks = alpha.mfs_by_score('2010-01-05', 200, 10) # 回测股票\n",
    "close = factor.get_secs_index('close', selected_stocks, trading_days) # 获取收盘价\n",
    "close\n",
    "stoploss = -0.1  # 止损阈值 \n",
    "stopprofit = 0.1  # 止盈阈值\n",
    "datelist = list(set(close.date))\n",
    "datelist = sorted(datelist)\n",
    "initial_date = datelist[0] # 建仓日\n",
    "ending_date = datelist[-1] # 强制平仓日\n",
    "raw = close[close.date == initial_date] # 建仓日成本信息\n",
    "raw = raw.rename(columns={'close': 'close_buy'})\n",
    "raw = raw.set_index('sec_id')\n",
    "records = raw.copy() # 存储持仓股票买卖价格\n",
    "records['close_sell'] = np.nan\n",
    "records['date_sell'] = np.nan\n",
    "close_new = pd.DataFrame()\n",
    "\n",
    "for date in datelist[1:]:  \n",
    "    now = close[close.date == date]\n",
    "    now = now.set_index('sec_id')\n",
    "    if date == ending_date:\n",
    "        stocks_hold_to_maturity = records[records.close_sell.isnull()].index.tolist()  # 获取在强制平仓日仍持仓的股票列表\n",
    "        sellstocks = now.loc[stocks_hold_to_maturity]\n",
    "        sellstocks = sellstocks.rename(columns={'close': 'close_sell'})\n",
    "        sellstocks['date_sell'] = date\n",
    "        print('ss', sellstocks)\n",
    "        records.update(sellstocks)\n",
    "        continue\n",
    "    else:\n",
    "        # 获取截至今日的浮动盈亏率\n",
    "        now = now.rename(columns={'close': 'close_now'})\n",
    "        del now['date']\n",
    "        close_all = raw.merge(now, how='left', left_index=True, right_index=True)\n",
    "        close_all['ret_rate'] = close_all['close_now'] / close_all['close_buy'] - 1\n",
    "        close_all = close_all.replace(np.nan, 0)  # 对于那些当日未取得股价的股票设置收益率为0 这样既不会被止损卖出也不会被止盈卖出\n",
    "        # 计算止损卖出的股票并存入records\n",
    "        sellstocks = close_all[close_all.ret_rate < stoploss]\n",
    "        if len(sellstocks) != 0:\n",
    "            dk.Logger.info(\"以下股票由于亏损大于{}被强制卖出: {}\".format(stoploss, sellstocks.index.tolist()))\n",
    "            sellstocks = sellstocks.rename(columns={'close_now': 'close_sell'})\n",
    "            sellstocks['date_sell'] = date\n",
    "            del sellstocks['close_buy']\n",
    "            records.update(sellstocks)\n",
    "        # 计算止盈卖出的股票并存入records\n",
    "        sellstocks = close_all[close_all.ret_rate > stopprofit]\n",
    "        if len(sellstocks) != 0:\n",
    "            dk.Logger.info(\"以下股票由于盈利大于{}被强制卖出: {}\".format(stopprofit, sellstocks.index.tolist()))\n",
    "            sellstocks = sellstocks.rename(columns={'close_now': 'close_sell'})\n",
    "            sellstocks['date_sell'] = date\n",
    "            del sellstocks['close_buy']\n",
    "            records.update(sellstocks)\n",
    "        bools = (close_all.ret_rate >= stoploss) & (close_all.ret_rate <= stopprofit)\n",
    "        close_new = close_all[bools]\n",
    "        if len(close_new) == 0: # 到期日前股票全部卖完\n",
    "            break\n",
    "        # close_new = close_new[close_all.ret_rate <= stopprofit]\n",
    "        del close_new['close_now']\n",
    "        del close_new['ret_rate']\n",
    "        raw = close_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971588333081457"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.close_sell.sum() / records.close_buy.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = factor.get_secs_index('close', ['000300.SH'], trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-33e4ec080a00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\06_software\\Anoconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\06_software\\Anoconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   2475\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2476\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 2477\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   2478\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "close.close.tail(1)[0] / close.close.head(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88488213917683978"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close.iloc[-1, 2] / close.iloc[0, 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame({'A': [1,2,3,4], 'B': [11,22,np.nan,44], 'C': [111, np.nan, 333,444]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame({'B':[33]}, index=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23455, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    B\n",
       "2 NaN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.loc[c.index, c.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.update(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>444.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A     B      C\n",
       "0  1  11.0  111.0\n",
       "1  2  22.0    NaN\n",
       "2  3  33.0  333.0\n",
       "3  4  44.0  444.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datelist = list(set(close.date))\n",
    "datelist = sorted(datelist)\n",
    "initial_date = datelist[0]\n",
    "raw = close[close.date == initial_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = close[close.date == '2010-01-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = raw.merge(now,how='left', on='sec_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_x</th>\n",
       "      <th>sec_id</th>\n",
       "      <th>close_x</th>\n",
       "      <th>date_y</th>\n",
       "      <th>close_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000049.SZ</td>\n",
       "      <td>6.85</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000417.SZ</td>\n",
       "      <td>8.44</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000559.SZ</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000601.SZ</td>\n",
       "      <td>6.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000650.SZ</td>\n",
       "      <td>4.62</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000687.SZ</td>\n",
       "      <td>7.77</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000751.SZ</td>\n",
       "      <td>6.89</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>6.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000810.SZ</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000876.SZ</td>\n",
       "      <td>5.47</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000902.SZ</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>000966.SZ</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>001696.SZ</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002022.SZ</td>\n",
       "      <td>16.06</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>14.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002032.SZ</td>\n",
       "      <td>9.68</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002081.SZ</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002099.SZ</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002100.SZ</td>\n",
       "      <td>4.74</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002104.SZ</td>\n",
       "      <td>8.60</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>8.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002124.SZ</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002157.SZ</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002242.SZ</td>\n",
       "      <td>13.29</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>12.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002267.SZ</td>\n",
       "      <td>9.98</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002275.SZ</td>\n",
       "      <td>17.96</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>17.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002276.SZ</td>\n",
       "      <td>7.89</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>7.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002285.SZ</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002299.SZ</td>\n",
       "      <td>11.98</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>12.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002303.SZ</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>002327.SZ</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>300009.SZ</td>\n",
       "      <td>5.29</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>300015.SZ</td>\n",
       "      <td>4.34</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>300016.SZ</td>\n",
       "      <td>7.28</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600011.SH</td>\n",
       "      <td>5.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600052.SH</td>\n",
       "      <td>7.84</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600066.SH</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600074.SH</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600129.SH</td>\n",
       "      <td>9.88</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>9.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600162.SH</td>\n",
       "      <td>5.16</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600176.SH</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>5.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600229.SH</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600240.SH</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600252.SH</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600261.SH</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600270.SH</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600299.SH</td>\n",
       "      <td>13.08</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>13.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600305.SH</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600307.SH</td>\n",
       "      <td>7.14</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600398.SH</td>\n",
       "      <td>4.76</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600499.SH</td>\n",
       "      <td>8.28</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600597.SH</td>\n",
       "      <td>8.83</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>8.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600600.SH</td>\n",
       "      <td>34.32</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>33.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600676.SH</td>\n",
       "      <td>7.55</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>7.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600894.SH</td>\n",
       "      <td>7.01</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>600987.SH</td>\n",
       "      <td>4.91</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>601872.SH</td>\n",
       "      <td>4.79</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date_x     sec_id  close_x      date_y  close_y\n",
       "0   2010-01-04  000049.SZ     6.85  2010-01-11     7.03\n",
       "1   2010-01-04  000417.SZ     8.44  2010-01-11     8.10\n",
       "2   2010-01-04  000559.SZ     2.90  2010-01-11     2.74\n",
       "3   2010-01-04  000601.SZ     6.35           0     0.00\n",
       "4   2010-01-04  000650.SZ     4.62  2010-01-11     4.51\n",
       "5   2010-01-04  000687.SZ     7.77  2010-01-11     7.69\n",
       "6   2010-01-04  000751.SZ     6.89  2010-01-11     6.73\n",
       "7   2010-01-04  000810.SZ     5.20  2010-01-11     4.96\n",
       "8   2010-01-04  000876.SZ     5.47  2010-01-11     5.25\n",
       "9   2010-01-04  000902.SZ     3.77  2010-01-11     4.65\n",
       "10  2010-01-04  000966.SZ     2.59  2010-01-11     2.65\n",
       "11  2010-01-04  001696.SZ     9.75           0     0.00\n",
       "12  2010-01-04  002022.SZ    16.06  2010-01-11    14.84\n",
       "13  2010-01-04  002032.SZ     9.68  2010-01-11     9.35\n",
       "14  2010-01-04  002081.SZ     2.53  2010-01-11     2.76\n",
       "15  2010-01-04  002099.SZ     2.88  2010-01-11     3.12\n",
       "16  2010-01-04  002100.SZ     4.74  2010-01-11     5.17\n",
       "17  2010-01-04  002104.SZ     8.60  2010-01-11     8.36\n",
       "18  2010-01-04  002124.SZ     4.36  2010-01-11     4.38\n",
       "19  2010-01-04  002157.SZ     2.43  2010-01-11     2.44\n",
       "20  2010-01-04  002242.SZ    13.29  2010-01-11    12.70\n",
       "21  2010-01-04  002267.SZ     9.98  2010-01-11     9.80\n",
       "22  2010-01-04  002275.SZ    17.96  2010-01-11    17.63\n",
       "23  2010-01-04  002276.SZ     7.89  2010-01-11     7.79\n",
       "24  2010-01-04  002285.SZ     3.82  2010-01-11     3.60\n",
       "25  2010-01-04  002299.SZ    11.98  2010-01-11    12.12\n",
       "26  2010-01-04  002303.SZ     3.84           0     0.00\n",
       "27  2010-01-04  002327.SZ     4.60  2010-01-11     4.75\n",
       "28  2010-01-04  300009.SZ     5.29  2010-01-11     4.88\n",
       "29  2010-01-04  300015.SZ     4.34  2010-01-11     4.22\n",
       "30  2010-01-04  300016.SZ     7.28  2010-01-11     6.65\n",
       "31  2010-01-04  600011.SH     5.84           0     0.00\n",
       "32  2010-01-04  600052.SH     7.84  2010-01-11     7.85\n",
       "33  2010-01-04  600066.SH     4.95  2010-01-11     4.64\n",
       "34  2010-01-04  600074.SH     3.50  2010-01-11     3.41\n",
       "35  2010-01-04  600129.SH     9.88  2010-01-11     9.36\n",
       "36  2010-01-04  600162.SH     5.16  2010-01-11     4.92\n",
       "37  2010-01-04  600176.SH     4.36  2010-01-11     5.22\n",
       "38  2010-01-04  600229.SH     7.00  2010-01-11     7.03\n",
       "39  2010-01-04  600240.SH     3.51  2010-01-11     3.56\n",
       "40  2010-01-04  600252.SH     2.08  2010-01-11     2.05\n",
       "41  2010-01-04  600261.SH     3.51  2010-01-11     3.62\n",
       "42  2010-01-04  600270.SH     7.50  2010-01-11     8.12\n",
       "43  2010-01-04  600299.SH    13.08  2010-01-11    13.60\n",
       "44  2010-01-04  600305.SH     3.25  2010-01-11     3.09\n",
       "45  2010-01-04  600307.SH     7.14  2010-01-11     6.60\n",
       "46  2010-01-04  600398.SH     4.76  2010-01-11     4.61\n",
       "47  2010-01-04  600499.SH     8.28  2010-01-11     8.50\n",
       "48  2010-01-04  600597.SH     8.83  2010-01-11     8.18\n",
       "49  2010-01-04  600600.SH    34.32  2010-01-11    33.04\n",
       "50  2010-01-04  600676.SH     7.55  2010-01-11     7.96\n",
       "51  2010-01-04  600894.SH     7.01  2010-01-11     6.89\n",
       "52  2010-01-04  600987.SH     4.91  2010-01-11     4.86\n",
       "53  2010-01-04  601872.SH     4.79  2010-01-11     4.92"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_all = raw.merge(now, how='inner', on='sec_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_all['ret_rate'] = close_all['close_now'] / close_all['close'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_new = close_all[close_all.ret_rate >= -0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\pymysql\\cursors.py:165: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 480\")\n",
      "  result = self._query(query)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\pymysql\\cursors.py:165: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "dk.df2mysql('root', '123888', 'index', 'calendar', calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indes_stds = ['return_rate_180days_std', 'return_rate_90days_std', 'return_rate_30days_std', 'return_rate_5days_std', 'vol_180days_std', 'vol_90days_std', 'vol_30days_std', 'vol_5days_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = factor.get_secs_multiple_index_stds(indes_stds, seleted_stocks, trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocks=alpha.mfs_by_score('2010-01-06', 200, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close = factor.get_secs_index('close', seleted_stocks, fk.get_trading_days('2014-01-01', '2017-01-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close = close.sort_values(['sec_id', 'date'])\n",
    "close = close.reset_index()\n",
    "del close['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close = close.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del close['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = close.copy()\n",
    "for sec_id in set(close.sec_id.tolist()):\n",
    "    temp = close[close.sec_id == sec_id]\n",
    "    for idx in temp.index[:-20]:\n",
    "        date_now = char2datetime(temp.loc[idx, 'date'])\n",
    "        date_future = char2datetime(temp.loc[idx+20, 'date'])\n",
    "        timedelta = (date_future - date_now).days\n",
    "        output.loc[idx, 'time_delta'] = timedelta\n",
    "        output.loc[idx, 'close_future'] = temp.loc[idx+20, 'close']\n",
    "        output.loc[idx, 'future_ret'] = (temp.loc[idx+20, 'close'] / temp.loc[idx, 'close'] - 1) /timedelta*365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.time_delta.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output1 = output[output.time_delta<=output.time_delta.mode()[0]]  # 删除异常股票 间隔时间太长可能由于停牌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sec_id</th>\n",
       "      <th>close</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>close_future</th>\n",
       "      <th>future_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>000049.SZ</td>\n",
       "      <td>47.76</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42.36</td>\n",
       "      <td>-1.473887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-02-07</td>\n",
       "      <td>000049.SZ</td>\n",
       "      <td>42.81</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.78</td>\n",
       "      <td>-1.836145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014-02-10</td>\n",
       "      <td>000049.SZ</td>\n",
       "      <td>46.74</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.68</td>\n",
       "      <td>-3.084617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     sec_id  close  time_delta  close_future  future_ret\n",
       "0   2014-01-02  000049.SZ  47.76        28.0         42.36   -1.473887\n",
       "21  2014-02-07  000049.SZ  42.81        28.0         36.78   -1.836145\n",
       "22  2014-02-10  000049.SZ  46.74        28.0         35.68   -3.084617"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sec_id</th>\n",
       "      <th>return_rate_180days_std</th>\n",
       "      <th>return_rate_90days_std</th>\n",
       "      <th>return_rate_30days_std</th>\n",
       "      <th>return_rate_5days_std</th>\n",
       "      <th>vol_180days_std</th>\n",
       "      <th>vol_90days_std</th>\n",
       "      <th>vol_30days_std</th>\n",
       "      <th>vol_5days_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>000049.SZ</td>\n",
       "      <td>-1.356756</td>\n",
       "      <td>-1.307882</td>\n",
       "      <td>-0.768149</td>\n",
       "      <td>-0.231596</td>\n",
       "      <td>1.001563</td>\n",
       "      <td>1.189773</td>\n",
       "      <td>2.032585</td>\n",
       "      <td>0.919646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>000417.SZ</td>\n",
       "      <td>0.334049</td>\n",
       "      <td>0.690060</td>\n",
       "      <td>1.289394</td>\n",
       "      <td>2.233196</td>\n",
       "      <td>-0.558611</td>\n",
       "      <td>-0.501178</td>\n",
       "      <td>-0.380362</td>\n",
       "      <td>0.328883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>000559.SZ</td>\n",
       "      <td>-0.079967</td>\n",
       "      <td>-0.992380</td>\n",
       "      <td>-0.441277</td>\n",
       "      <td>0.135561</td>\n",
       "      <td>0.279298</td>\n",
       "      <td>-0.449468</td>\n",
       "      <td>0.093655</td>\n",
       "      <td>-0.336278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     sec_id  return_rate_180days_std  return_rate_90days_std  \\\n",
       "0  2015-01-05  000049.SZ                -1.356756               -1.307882   \n",
       "1  2015-01-05  000417.SZ                 0.334049                0.690060   \n",
       "2  2015-01-05  000559.SZ                -0.079967               -0.992380   \n",
       "\n",
       "   return_rate_30days_std  return_rate_5days_std  vol_180days_std  \\\n",
       "0               -0.768149              -0.231596         1.001563   \n",
       "1                1.289394               2.233196        -0.558611   \n",
       "2               -0.441277               0.135561         0.279298   \n",
       "\n",
       "   vol_90days_std  vol_30days_std  vol_5days_std  \n",
       "0        1.189773        2.032585       0.919646  \n",
       "1       -0.501178       -0.380362       0.328883  \n",
       "2       -0.449468        0.093655      -0.336278  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1 = train.merge(output1[['date','sec_id','future_ret']], how='inner', on=['date','sec_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qua = train1['future_ret'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1837983026023942"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1['goodyn'] = train1['future_ret'].apply(lambda x: 1 if x > qua else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_final = train1.copy()\n",
    "del train_final['date']\n",
    "del train_final['sec_id']\n",
    "del train_final['future_ret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_final.to_csv(r\"E:\\99_daily\\TODAY\\formal_db\\train_final.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_final = pd.read_csv(r\"E:\\99_daily\\TODAY\\formal_db\\train_final.csv\",encoding='utf-8', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_final.iloc[:, :-1].copy()\n",
    "y = train_final.iloc[:, -1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未调参前10折的平均查准率 0.441455785712\n"
     ]
    }
   ],
   "source": [
    "xgb_no_prun = xgb.XGBClassifier()\n",
    "scores_roc1 = model_selection.cross_val_score(xgb_no_prun, train_final.iloc[:, :-1], train_final.iloc[:, -1], cv=10, scoring='precision')\n",
    "print(\"未调参前10折的平均查准率\",scores_roc1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = xgb.XGBClassifier(seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 40),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.78379359670008275,\n",
       " 'gamma': 8.8331131698793151,\n",
       " 'learning_rate': 0.061088575702060721,\n",
       " 'max_depth': 17,\n",
       " 'min_child_weight': 14.524167698779559,\n",
       " 'n_estimators': 17,\n",
       " 'reg_alpha': 329.7524018497852,\n",
       " 'subsample': 0.93861304854237471}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_model_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-9276adac884e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_model_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_model_'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "gs = RandomizedSearchCV(xgb, params, n_jobs=4)  \n",
    "gs.fit(train_final.iloc[:, :-1], train_final.iloc[:, -1])  \n",
    "gs.best_model_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bets_params = gs.best_params_\n",
    "xgb_new = xgb.XGBClassifier(objective= 'binary:logistic', **bets_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.78379359670008275, gamma=8.8331131698793151,\n",
       "       learning_rate=0.061088575702060721, max_delta_step=0, max_depth=17,\n",
       "       min_child_weight=14.524167698779559, missing=None, n_estimators=17,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=329.7524018497852, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.93861304854237471)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_new.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = xgb_new.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [i for i in range(10, 100,5)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_ada = GridSearchCV(ada, param_grid=param_grid, scoring = 'precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.28962, std: 0.14297, params: {'n_estimators': 10},\n",
       "  mean: 0.28584, std: 0.10433, params: {'n_estimators': 15},\n",
       "  mean: 0.31384, std: 0.08481, params: {'n_estimators': 20},\n",
       "  mean: 0.30383, std: 0.07120, params: {'n_estimators': 25},\n",
       "  mean: 0.25328, std: 0.09702, params: {'n_estimators': 30},\n",
       "  mean: 0.25996, std: 0.09117, params: {'n_estimators': 35},\n",
       "  mean: 0.26135, std: 0.09539, params: {'n_estimators': 40},\n",
       "  mean: 0.29207, std: 0.10946, params: {'n_estimators': 45},\n",
       "  mean: 0.30092, std: 0.09830, params: {'n_estimators': 50},\n",
       "  mean: 0.29668, std: 0.12482, params: {'n_estimators': 55},\n",
       "  mean: 0.28818, std: 0.11419, params: {'n_estimators': 60},\n",
       "  mean: 0.29263, std: 0.11088, params: {'n_estimators': 65},\n",
       "  mean: 0.29082, std: 0.09636, params: {'n_estimators': 70},\n",
       "  mean: 0.27836, std: 0.09005, params: {'n_estimators': 75},\n",
       "  mean: 0.28530, std: 0.08755, params: {'n_estimators': 80},\n",
       "  mean: 0.26998, std: 0.08347, params: {'n_estimators': 85},\n",
       "  mean: 0.28259, std: 0.08974, params: {'n_estimators': 90},\n",
       "  mean: 0.29047, std: 0.10334, params: {'n_estimators': 95}],\n",
       " {'n_estimators': 20},\n",
       " 0.31384101185448571)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_ada.fit(X,y)\n",
    "grid_search_ada.grid_scores_, grid_search_ada.best_params_,     grid_search_ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_new = AdaBoostClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_new.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48072525,  0.51927475],\n",
       "       [ 0.53275588,  0.46724412],\n",
       "       [ 0.53469403,  0.46530597],\n",
       "       ..., \n",
       "       [ 0.52601347,  0.47398653],\n",
       "       [ 0.54887273,  0.45112727],\n",
       "       [ 0.54887273,  0.45112727]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_new.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return_rate_180days_std</th>\n",
       "      <th>return_rate_90days_std</th>\n",
       "      <th>return_rate_30days_std</th>\n",
       "      <th>return_rate_5days_std</th>\n",
       "      <th>vol_180days_std</th>\n",
       "      <th>vol_90days_std</th>\n",
       "      <th>vol_30days_std</th>\n",
       "      <th>vol_5days_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.356756</td>\n",
       "      <td>-1.307882</td>\n",
       "      <td>-0.768149</td>\n",
       "      <td>-0.231596</td>\n",
       "      <td>1.001563</td>\n",
       "      <td>1.189773</td>\n",
       "      <td>2.032585</td>\n",
       "      <td>0.919646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.334049</td>\n",
       "      <td>0.690060</td>\n",
       "      <td>1.289394</td>\n",
       "      <td>2.233196</td>\n",
       "      <td>-0.558611</td>\n",
       "      <td>-0.501178</td>\n",
       "      <td>-0.380362</td>\n",
       "      <td>0.328883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.079967</td>\n",
       "      <td>-0.992380</td>\n",
       "      <td>-0.441277</td>\n",
       "      <td>0.135561</td>\n",
       "      <td>0.279298</td>\n",
       "      <td>-0.449468</td>\n",
       "      <td>0.093655</td>\n",
       "      <td>-0.336278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040342</td>\n",
       "      <td>0.253545</td>\n",
       "      <td>-0.469414</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.465204</td>\n",
       "      <td>-0.360556</td>\n",
       "      <td>-0.678038</td>\n",
       "      <td>-0.605512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.183296</td>\n",
       "      <td>0.689847</td>\n",
       "      <td>-0.133713</td>\n",
       "      <td>0.333625</td>\n",
       "      <td>-0.317903</td>\n",
       "      <td>-0.287216</td>\n",
       "      <td>-0.716403</td>\n",
       "      <td>-0.736631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.807113</td>\n",
       "      <td>-1.099842</td>\n",
       "      <td>-0.291435</td>\n",
       "      <td>0.615900</td>\n",
       "      <td>0.430955</td>\n",
       "      <td>-0.592694</td>\n",
       "      <td>-0.590572</td>\n",
       "      <td>-0.485846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.886582</td>\n",
       "      <td>-1.069732</td>\n",
       "      <td>-0.727913</td>\n",
       "      <td>0.272884</td>\n",
       "      <td>-0.225753</td>\n",
       "      <td>-0.226798</td>\n",
       "      <td>-0.126306</td>\n",
       "      <td>-0.631493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.370789</td>\n",
       "      <td>-0.691973</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>-0.108104</td>\n",
       "      <td>-0.696172</td>\n",
       "      <td>-0.725821</td>\n",
       "      <td>-0.730246</td>\n",
       "      <td>-0.379442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.348441</td>\n",
       "      <td>0.834564</td>\n",
       "      <td>0.478190</td>\n",
       "      <td>0.330467</td>\n",
       "      <td>-0.240203</td>\n",
       "      <td>-0.229254</td>\n",
       "      <td>-0.496601</td>\n",
       "      <td>-0.575361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.383566</td>\n",
       "      <td>1.527724</td>\n",
       "      <td>1.357040</td>\n",
       "      <td>0.265829</td>\n",
       "      <td>-0.415549</td>\n",
       "      <td>-0.183727</td>\n",
       "      <td>-0.317572</td>\n",
       "      <td>-0.703449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.280932</td>\n",
       "      <td>0.888364</td>\n",
       "      <td>-0.453893</td>\n",
       "      <td>-0.645558</td>\n",
       "      <td>0.290326</td>\n",
       "      <td>0.140745</td>\n",
       "      <td>-0.146096</td>\n",
       "      <td>0.034627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.081824</td>\n",
       "      <td>-1.087920</td>\n",
       "      <td>-0.657123</td>\n",
       "      <td>-0.388324</td>\n",
       "      <td>0.440393</td>\n",
       "      <td>0.672364</td>\n",
       "      <td>0.551548</td>\n",
       "      <td>0.102613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.333597</td>\n",
       "      <td>-0.186444</td>\n",
       "      <td>-0.024972</td>\n",
       "      <td>0.165255</td>\n",
       "      <td>-0.239626</td>\n",
       "      <td>-0.288822</td>\n",
       "      <td>-0.642612</td>\n",
       "      <td>-0.284260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.391783</td>\n",
       "      <td>-0.295832</td>\n",
       "      <td>0.168529</td>\n",
       "      <td>1.497364</td>\n",
       "      <td>0.178766</td>\n",
       "      <td>-0.494694</td>\n",
       "      <td>-0.363788</td>\n",
       "      <td>0.659071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.862848</td>\n",
       "      <td>0.147292</td>\n",
       "      <td>-0.616607</td>\n",
       "      <td>0.207680</td>\n",
       "      <td>-0.491153</td>\n",
       "      <td>-0.519905</td>\n",
       "      <td>-0.636852</td>\n",
       "      <td>-0.747840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.472496</td>\n",
       "      <td>-0.830050</td>\n",
       "      <td>-0.439207</td>\n",
       "      <td>-0.151783</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>-0.282397</td>\n",
       "      <td>-0.273785</td>\n",
       "      <td>-0.411066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.701400</td>\n",
       "      <td>-1.238413</td>\n",
       "      <td>-1.196773</td>\n",
       "      <td>0.071407</td>\n",
       "      <td>-0.569848</td>\n",
       "      <td>-0.551200</td>\n",
       "      <td>-0.293427</td>\n",
       "      <td>-0.726021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.993159</td>\n",
       "      <td>-0.322077</td>\n",
       "      <td>0.068334</td>\n",
       "      <td>0.096841</td>\n",
       "      <td>-0.449904</td>\n",
       "      <td>-0.548839</td>\n",
       "      <td>-0.472043</td>\n",
       "      <td>-0.290886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.374929</td>\n",
       "      <td>-0.353624</td>\n",
       "      <td>-0.308467</td>\n",
       "      <td>0.108665</td>\n",
       "      <td>-0.277454</td>\n",
       "      <td>-0.446564</td>\n",
       "      <td>-0.460751</td>\n",
       "      <td>-0.338017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.565193</td>\n",
       "      <td>-0.340708</td>\n",
       "      <td>-0.526657</td>\n",
       "      <td>0.400069</td>\n",
       "      <td>0.246614</td>\n",
       "      <td>-0.090433</td>\n",
       "      <td>-0.035894</td>\n",
       "      <td>0.000683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.035417</td>\n",
       "      <td>-0.757854</td>\n",
       "      <td>-0.429306</td>\n",
       "      <td>-0.071556</td>\n",
       "      <td>-0.332497</td>\n",
       "      <td>-0.606906</td>\n",
       "      <td>-0.397043</td>\n",
       "      <td>-0.538051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.501224</td>\n",
       "      <td>1.145417</td>\n",
       "      <td>0.158498</td>\n",
       "      <td>2.168023</td>\n",
       "      <td>-0.198222</td>\n",
       "      <td>-0.145957</td>\n",
       "      <td>-0.202658</td>\n",
       "      <td>0.012651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.034674</td>\n",
       "      <td>-0.793933</td>\n",
       "      <td>-0.652247</td>\n",
       "      <td>-0.258642</td>\n",
       "      <td>0.286520</td>\n",
       "      <td>-0.399319</td>\n",
       "      <td>-0.375107</td>\n",
       "      <td>-0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.271605</td>\n",
       "      <td>-0.342845</td>\n",
       "      <td>-0.367274</td>\n",
       "      <td>-1.528163</td>\n",
       "      <td>-0.380913</td>\n",
       "      <td>-0.329509</td>\n",
       "      <td>-0.192953</td>\n",
       "      <td>0.529881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.506476</td>\n",
       "      <td>-0.523448</td>\n",
       "      <td>-0.084013</td>\n",
       "      <td>0.051432</td>\n",
       "      <td>-0.657329</td>\n",
       "      <td>-0.779240</td>\n",
       "      <td>-0.771087</td>\n",
       "      <td>-0.710080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.848200</td>\n",
       "      <td>-0.966308</td>\n",
       "      <td>-1.444299</td>\n",
       "      <td>-1.197438</td>\n",
       "      <td>0.229514</td>\n",
       "      <td>0.098808</td>\n",
       "      <td>0.560918</td>\n",
       "      <td>0.231855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.673462</td>\n",
       "      <td>-0.216465</td>\n",
       "      <td>-0.550485</td>\n",
       "      <td>-0.252101</td>\n",
       "      <td>1.076916</td>\n",
       "      <td>0.266448</td>\n",
       "      <td>-0.127416</td>\n",
       "      <td>-0.264905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.134157</td>\n",
       "      <td>0.164767</td>\n",
       "      <td>-0.537874</td>\n",
       "      <td>-0.771959</td>\n",
       "      <td>-0.388639</td>\n",
       "      <td>-0.286137</td>\n",
       "      <td>-0.675290</td>\n",
       "      <td>-0.482963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.584036</td>\n",
       "      <td>0.573377</td>\n",
       "      <td>0.680922</td>\n",
       "      <td>-2.405974</td>\n",
       "      <td>-0.316483</td>\n",
       "      <td>0.051093</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.463465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.807396</td>\n",
       "      <td>-0.480779</td>\n",
       "      <td>-0.450064</td>\n",
       "      <td>0.175031</td>\n",
       "      <td>-0.906623</td>\n",
       "      <td>-0.858691</td>\n",
       "      <td>-0.828440</td>\n",
       "      <td>-0.858946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18164</th>\n",
       "      <td>-0.762289</td>\n",
       "      <td>0.073582</td>\n",
       "      <td>-0.250555</td>\n",
       "      <td>-0.115396</td>\n",
       "      <td>-0.710422</td>\n",
       "      <td>-0.598540</td>\n",
       "      <td>-0.380638</td>\n",
       "      <td>-0.486991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18165</th>\n",
       "      <td>-0.286171</td>\n",
       "      <td>-0.382402</td>\n",
       "      <td>-0.426165</td>\n",
       "      <td>0.472379</td>\n",
       "      <td>-0.233610</td>\n",
       "      <td>-0.369415</td>\n",
       "      <td>-0.122472</td>\n",
       "      <td>-0.466208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18166</th>\n",
       "      <td>0.176451</td>\n",
       "      <td>0.160355</td>\n",
       "      <td>0.017864</td>\n",
       "      <td>0.410994</td>\n",
       "      <td>0.218681</td>\n",
       "      <td>-0.150901</td>\n",
       "      <td>-0.299949</td>\n",
       "      <td>-0.065183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18167</th>\n",
       "      <td>-0.688207</td>\n",
       "      <td>-0.164268</td>\n",
       "      <td>0.025902</td>\n",
       "      <td>-0.090327</td>\n",
       "      <td>-0.856291</td>\n",
       "      <td>-0.763218</td>\n",
       "      <td>-0.428906</td>\n",
       "      <td>-0.553772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18168</th>\n",
       "      <td>-0.020313</td>\n",
       "      <td>-0.391689</td>\n",
       "      <td>-0.304023</td>\n",
       "      <td>-0.287824</td>\n",
       "      <td>-0.544864</td>\n",
       "      <td>-0.712104</td>\n",
       "      <td>-0.342680</td>\n",
       "      <td>-0.319129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18169</th>\n",
       "      <td>-0.341190</td>\n",
       "      <td>-0.355255</td>\n",
       "      <td>-0.176820</td>\n",
       "      <td>-0.061448</td>\n",
       "      <td>-0.685845</td>\n",
       "      <td>-0.628646</td>\n",
       "      <td>-0.348171</td>\n",
       "      <td>-0.432570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18170</th>\n",
       "      <td>-0.294481</td>\n",
       "      <td>0.150294</td>\n",
       "      <td>0.273423</td>\n",
       "      <td>-0.186149</td>\n",
       "      <td>-0.500415</td>\n",
       "      <td>-0.497077</td>\n",
       "      <td>-0.250831</td>\n",
       "      <td>-0.383531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18171</th>\n",
       "      <td>-0.678552</td>\n",
       "      <td>0.083991</td>\n",
       "      <td>0.305265</td>\n",
       "      <td>0.295937</td>\n",
       "      <td>-0.811773</td>\n",
       "      <td>-0.692068</td>\n",
       "      <td>-0.367710</td>\n",
       "      <td>-0.565260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18172</th>\n",
       "      <td>-0.514029</td>\n",
       "      <td>-0.032661</td>\n",
       "      <td>-0.206107</td>\n",
       "      <td>-0.097182</td>\n",
       "      <td>-0.768232</td>\n",
       "      <td>-0.687057</td>\n",
       "      <td>-0.424647</td>\n",
       "      <td>-0.508334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18173</th>\n",
       "      <td>-0.575903</td>\n",
       "      <td>-0.603907</td>\n",
       "      <td>-0.551519</td>\n",
       "      <td>0.337512</td>\n",
       "      <td>-0.386718</td>\n",
       "      <td>-0.506682</td>\n",
       "      <td>-0.219617</td>\n",
       "      <td>-0.380183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18174</th>\n",
       "      <td>-0.784882</td>\n",
       "      <td>-0.406068</td>\n",
       "      <td>-0.020154</td>\n",
       "      <td>0.601889</td>\n",
       "      <td>-0.573512</td>\n",
       "      <td>-0.589531</td>\n",
       "      <td>-0.384812</td>\n",
       "      <td>-0.514104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18175</th>\n",
       "      <td>0.022050</td>\n",
       "      <td>-0.352875</td>\n",
       "      <td>-0.412744</td>\n",
       "      <td>0.127204</td>\n",
       "      <td>-0.539316</td>\n",
       "      <td>-0.558973</td>\n",
       "      <td>-0.322112</td>\n",
       "      <td>-0.481785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18176</th>\n",
       "      <td>-0.560829</td>\n",
       "      <td>0.256197</td>\n",
       "      <td>0.315914</td>\n",
       "      <td>0.026535</td>\n",
       "      <td>-0.868765</td>\n",
       "      <td>-0.766855</td>\n",
       "      <td>-0.421146</td>\n",
       "      <td>-0.567546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18177</th>\n",
       "      <td>-0.407202</td>\n",
       "      <td>-0.644909</td>\n",
       "      <td>-0.065399</td>\n",
       "      <td>0.340041</td>\n",
       "      <td>-0.716974</td>\n",
       "      <td>-0.576759</td>\n",
       "      <td>-0.417812</td>\n",
       "      <td>-0.513568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18178</th>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.089670</td>\n",
       "      <td>0.425444</td>\n",
       "      <td>0.513014</td>\n",
       "      <td>-0.593785</td>\n",
       "      <td>-0.514177</td>\n",
       "      <td>-0.298409</td>\n",
       "      <td>-0.513123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18179</th>\n",
       "      <td>0.086293</td>\n",
       "      <td>-0.219492</td>\n",
       "      <td>-0.147267</td>\n",
       "      <td>0.065147</td>\n",
       "      <td>-0.320893</td>\n",
       "      <td>-0.587528</td>\n",
       "      <td>-0.398770</td>\n",
       "      <td>-0.354935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>-0.317727</td>\n",
       "      <td>-0.072929</td>\n",
       "      <td>-0.245787</td>\n",
       "      <td>0.312627</td>\n",
       "      <td>-0.230293</td>\n",
       "      <td>-0.201526</td>\n",
       "      <td>-0.330352</td>\n",
       "      <td>-0.334054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>-1.018134</td>\n",
       "      <td>-0.272819</td>\n",
       "      <td>-0.297241</td>\n",
       "      <td>-0.154179</td>\n",
       "      <td>-0.652678</td>\n",
       "      <td>-0.551934</td>\n",
       "      <td>-0.387536</td>\n",
       "      <td>-0.510748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>-0.582748</td>\n",
       "      <td>-0.361880</td>\n",
       "      <td>-0.117349</td>\n",
       "      <td>0.060645</td>\n",
       "      <td>-0.561385</td>\n",
       "      <td>-0.654890</td>\n",
       "      <td>-0.376519</td>\n",
       "      <td>-0.421268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>-0.838003</td>\n",
       "      <td>-0.554139</td>\n",
       "      <td>-0.107513</td>\n",
       "      <td>-0.083515</td>\n",
       "      <td>-0.485983</td>\n",
       "      <td>-0.611996</td>\n",
       "      <td>-0.387639</td>\n",
       "      <td>-0.355161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>-0.099115</td>\n",
       "      <td>-0.097838</td>\n",
       "      <td>0.289654</td>\n",
       "      <td>0.452903</td>\n",
       "      <td>-0.829466</td>\n",
       "      <td>-0.751829</td>\n",
       "      <td>-0.394973</td>\n",
       "      <td>-0.587527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18185</th>\n",
       "      <td>-0.577965</td>\n",
       "      <td>0.077056</td>\n",
       "      <td>0.309391</td>\n",
       "      <td>0.304233</td>\n",
       "      <td>-0.792143</td>\n",
       "      <td>-0.682574</td>\n",
       "      <td>-0.358028</td>\n",
       "      <td>-0.532071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18186</th>\n",
       "      <td>-0.520117</td>\n",
       "      <td>-0.250962</td>\n",
       "      <td>-0.080338</td>\n",
       "      <td>0.353302</td>\n",
       "      <td>-0.631921</td>\n",
       "      <td>-0.599308</td>\n",
       "      <td>-0.392478</td>\n",
       "      <td>-0.423318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18187</th>\n",
       "      <td>-0.354763</td>\n",
       "      <td>0.070676</td>\n",
       "      <td>-0.103046</td>\n",
       "      <td>0.202096</td>\n",
       "      <td>-0.797014</td>\n",
       "      <td>-0.713651</td>\n",
       "      <td>-0.390451</td>\n",
       "      <td>-0.526104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18188</th>\n",
       "      <td>-0.172804</td>\n",
       "      <td>-0.035165</td>\n",
       "      <td>-0.360843</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.014679</td>\n",
       "      <td>-0.192370</td>\n",
       "      <td>-0.299580</td>\n",
       "      <td>-0.295317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18189</th>\n",
       "      <td>-0.622361</td>\n",
       "      <td>-0.199764</td>\n",
       "      <td>-0.112755</td>\n",
       "      <td>-0.078332</td>\n",
       "      <td>-0.725996</td>\n",
       "      <td>-0.672380</td>\n",
       "      <td>-0.411861</td>\n",
       "      <td>-0.465512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18190</th>\n",
       "      <td>-0.332176</td>\n",
       "      <td>-0.969995</td>\n",
       "      <td>-0.244427</td>\n",
       "      <td>-0.382433</td>\n",
       "      <td>-0.214506</td>\n",
       "      <td>-0.102144</td>\n",
       "      <td>-0.241372</td>\n",
       "      <td>-0.152149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18191</th>\n",
       "      <td>0.592463</td>\n",
       "      <td>-0.565587</td>\n",
       "      <td>0.068277</td>\n",
       "      <td>-0.367161</td>\n",
       "      <td>0.261902</td>\n",
       "      <td>0.091437</td>\n",
       "      <td>0.021193</td>\n",
       "      <td>-0.014833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18192</th>\n",
       "      <td>-0.302614</td>\n",
       "      <td>-0.312383</td>\n",
       "      <td>-0.046752</td>\n",
       "      <td>-0.340439</td>\n",
       "      <td>-0.598556</td>\n",
       "      <td>-0.471531</td>\n",
       "      <td>-0.250229</td>\n",
       "      <td>-0.211129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18193</th>\n",
       "      <td>-0.167167</td>\n",
       "      <td>-0.154078</td>\n",
       "      <td>0.185851</td>\n",
       "      <td>-0.256740</td>\n",
       "      <td>-0.493748</td>\n",
       "      <td>-0.333528</td>\n",
       "      <td>-0.136652</td>\n",
       "      <td>-0.177905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18194 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       return_rate_180days_std  return_rate_90days_std  \\\n",
       "0                    -1.356756               -1.307882   \n",
       "1                     0.334049                0.690060   \n",
       "2                    -0.079967               -0.992380   \n",
       "3                    -0.040342                0.253545   \n",
       "4                     0.183296                0.689847   \n",
       "5                     1.807113               -1.099842   \n",
       "6                    -0.886582               -1.069732   \n",
       "7                    -0.370789               -0.691973   \n",
       "8                     0.348441                0.834564   \n",
       "9                     1.383566                1.527724   \n",
       "10                    0.280932                0.888364   \n",
       "11                   -1.081824               -1.087920   \n",
       "12                   -0.333597               -0.186444   \n",
       "13                    0.391783               -0.295832   \n",
       "14                   -0.862848                0.147292   \n",
       "15                   -0.472496               -0.830050   \n",
       "16                   -0.701400               -1.238413   \n",
       "17                   -0.993159               -0.322077   \n",
       "18                   -0.374929               -0.353624   \n",
       "19                   -0.565193               -0.340708   \n",
       "20                   -0.035417               -0.757854   \n",
       "21                    0.501224                1.145417   \n",
       "22                    0.034674               -0.793933   \n",
       "23                   -0.271605               -0.342845   \n",
       "24                   -0.506476               -0.523448   \n",
       "25                   -0.848200               -0.966308   \n",
       "26                    0.673462               -0.216465   \n",
       "27                   -0.134157                0.164767   \n",
       "28                    0.584036                0.573377   \n",
       "29                   -0.807396               -0.480779   \n",
       "...                        ...                     ...   \n",
       "18164                -0.762289                0.073582   \n",
       "18165                -0.286171               -0.382402   \n",
       "18166                 0.176451                0.160355   \n",
       "18167                -0.688207               -0.164268   \n",
       "18168                -0.020313               -0.391689   \n",
       "18169                -0.341190               -0.355255   \n",
       "18170                -0.294481                0.150294   \n",
       "18171                -0.678552                0.083991   \n",
       "18172                -0.514029               -0.032661   \n",
       "18173                -0.575903               -0.603907   \n",
       "18174                -0.784882               -0.406068   \n",
       "18175                 0.022050               -0.352875   \n",
       "18176                -0.560829                0.256197   \n",
       "18177                -0.407202               -0.644909   \n",
       "18178                 0.026571                0.089670   \n",
       "18179                 0.086293               -0.219492   \n",
       "18180                -0.317727               -0.072929   \n",
       "18181                -1.018134               -0.272819   \n",
       "18182                -0.582748               -0.361880   \n",
       "18183                -0.838003               -0.554139   \n",
       "18184                -0.099115               -0.097838   \n",
       "18185                -0.577965                0.077056   \n",
       "18186                -0.520117               -0.250962   \n",
       "18187                -0.354763                0.070676   \n",
       "18188                -0.172804               -0.035165   \n",
       "18189                -0.622361               -0.199764   \n",
       "18190                -0.332176               -0.969995   \n",
       "18191                 0.592463               -0.565587   \n",
       "18192                -0.302614               -0.312383   \n",
       "18193                -0.167167               -0.154078   \n",
       "\n",
       "       return_rate_30days_std  return_rate_5days_std  vol_180days_std  \\\n",
       "0                   -0.768149              -0.231596         1.001563   \n",
       "1                    1.289394               2.233196        -0.558611   \n",
       "2                   -0.441277               0.135561         0.279298   \n",
       "3                   -0.469414               0.094596        -0.465204   \n",
       "4                   -0.133713               0.333625        -0.317903   \n",
       "5                   -0.291435               0.615900         0.430955   \n",
       "6                   -0.727913               0.272884        -0.225753   \n",
       "7                    0.006051              -0.108104        -0.696172   \n",
       "8                    0.478190               0.330467        -0.240203   \n",
       "9                    1.357040               0.265829        -0.415549   \n",
       "10                  -0.453893              -0.645558         0.290326   \n",
       "11                  -0.657123              -0.388324         0.440393   \n",
       "12                  -0.024972               0.165255        -0.239626   \n",
       "13                   0.168529               1.497364         0.178766   \n",
       "14                  -0.616607               0.207680        -0.491153   \n",
       "15                  -0.439207              -0.151783        -0.003798   \n",
       "16                  -1.196773               0.071407        -0.569848   \n",
       "17                   0.068334               0.096841        -0.449904   \n",
       "18                  -0.308467               0.108665        -0.277454   \n",
       "19                  -0.526657               0.400069         0.246614   \n",
       "20                  -0.429306              -0.071556        -0.332497   \n",
       "21                   0.158498               2.168023        -0.198222   \n",
       "22                  -0.652247              -0.258642         0.286520   \n",
       "23                  -0.367274              -1.528163        -0.380913   \n",
       "24                  -0.084013               0.051432        -0.657329   \n",
       "25                  -1.444299              -1.197438         0.229514   \n",
       "26                  -0.550485              -0.252101         1.076916   \n",
       "27                  -0.537874              -0.771959        -0.388639   \n",
       "28                   0.680922              -2.405974        -0.316483   \n",
       "29                  -0.450064               0.175031        -0.906623   \n",
       "...                       ...                    ...              ...   \n",
       "18164               -0.250555              -0.115396        -0.710422   \n",
       "18165               -0.426165               0.472379        -0.233610   \n",
       "18166                0.017864               0.410994         0.218681   \n",
       "18167                0.025902              -0.090327        -0.856291   \n",
       "18168               -0.304023              -0.287824        -0.544864   \n",
       "18169               -0.176820              -0.061448        -0.685845   \n",
       "18170                0.273423              -0.186149        -0.500415   \n",
       "18171                0.305265               0.295937        -0.811773   \n",
       "18172               -0.206107              -0.097182        -0.768232   \n",
       "18173               -0.551519               0.337512        -0.386718   \n",
       "18174               -0.020154               0.601889        -0.573512   \n",
       "18175               -0.412744               0.127204        -0.539316   \n",
       "18176                0.315914               0.026535        -0.868765   \n",
       "18177               -0.065399               0.340041        -0.716974   \n",
       "18178                0.425444               0.513014        -0.593785   \n",
       "18179               -0.147267               0.065147        -0.320893   \n",
       "18180               -0.245787               0.312627        -0.230293   \n",
       "18181               -0.297241              -0.154179        -0.652678   \n",
       "18182               -0.117349               0.060645        -0.561385   \n",
       "18183               -0.107513              -0.083515        -0.485983   \n",
       "18184                0.289654               0.452903        -0.829466   \n",
       "18185                0.309391               0.304233        -0.792143   \n",
       "18186               -0.080338               0.353302        -0.631921   \n",
       "18187               -0.103046               0.202096        -0.797014   \n",
       "18188               -0.360843              -0.080021        -0.014679   \n",
       "18189               -0.112755              -0.078332        -0.725996   \n",
       "18190               -0.244427              -0.382433        -0.214506   \n",
       "18191                0.068277              -0.367161         0.261902   \n",
       "18192               -0.046752              -0.340439        -0.598556   \n",
       "18193                0.185851              -0.256740        -0.493748   \n",
       "\n",
       "       vol_90days_std  vol_30days_std  vol_5days_std  \n",
       "0            1.189773        2.032585       0.919646  \n",
       "1           -0.501178       -0.380362       0.328883  \n",
       "2           -0.449468        0.093655      -0.336278  \n",
       "3           -0.360556       -0.678038      -0.605512  \n",
       "4           -0.287216       -0.716403      -0.736631  \n",
       "5           -0.592694       -0.590572      -0.485846  \n",
       "6           -0.226798       -0.126306      -0.631493  \n",
       "7           -0.725821       -0.730246      -0.379442  \n",
       "8           -0.229254       -0.496601      -0.575361  \n",
       "9           -0.183727       -0.317572      -0.703449  \n",
       "10           0.140745       -0.146096       0.034627  \n",
       "11           0.672364        0.551548       0.102613  \n",
       "12          -0.288822       -0.642612      -0.284260  \n",
       "13          -0.494694       -0.363788       0.659071  \n",
       "14          -0.519905       -0.636852      -0.747840  \n",
       "15          -0.282397       -0.273785      -0.411066  \n",
       "16          -0.551200       -0.293427      -0.726021  \n",
       "17          -0.548839       -0.472043      -0.290886  \n",
       "18          -0.446564       -0.460751      -0.338017  \n",
       "19          -0.090433       -0.035894       0.000683  \n",
       "20          -0.606906       -0.397043      -0.538051  \n",
       "21          -0.145957       -0.202658       0.012651  \n",
       "22          -0.399319       -0.375107      -0.002984  \n",
       "23          -0.329509       -0.192953       0.529881  \n",
       "24          -0.779240       -0.771087      -0.710080  \n",
       "25           0.098808        0.560918       0.231855  \n",
       "26           0.266448       -0.127416      -0.264905  \n",
       "27          -0.286137       -0.675290      -0.482963  \n",
       "28           0.051093        0.002908       0.463465  \n",
       "29          -0.858691       -0.828440      -0.858946  \n",
       "...               ...             ...            ...  \n",
       "18164       -0.598540       -0.380638      -0.486991  \n",
       "18165       -0.369415       -0.122472      -0.466208  \n",
       "18166       -0.150901       -0.299949      -0.065183  \n",
       "18167       -0.763218       -0.428906      -0.553772  \n",
       "18168       -0.712104       -0.342680      -0.319129  \n",
       "18169       -0.628646       -0.348171      -0.432570  \n",
       "18170       -0.497077       -0.250831      -0.383531  \n",
       "18171       -0.692068       -0.367710      -0.565260  \n",
       "18172       -0.687057       -0.424647      -0.508334  \n",
       "18173       -0.506682       -0.219617      -0.380183  \n",
       "18174       -0.589531       -0.384812      -0.514104  \n",
       "18175       -0.558973       -0.322112      -0.481785  \n",
       "18176       -0.766855       -0.421146      -0.567546  \n",
       "18177       -0.576759       -0.417812      -0.513568  \n",
       "18178       -0.514177       -0.298409      -0.513123  \n",
       "18179       -0.587528       -0.398770      -0.354935  \n",
       "18180       -0.201526       -0.330352      -0.334054  \n",
       "18181       -0.551934       -0.387536      -0.510748  \n",
       "18182       -0.654890       -0.376519      -0.421268  \n",
       "18183       -0.611996       -0.387639      -0.355161  \n",
       "18184       -0.751829       -0.394973      -0.587527  \n",
       "18185       -0.682574       -0.358028      -0.532071  \n",
       "18186       -0.599308       -0.392478      -0.423318  \n",
       "18187       -0.713651       -0.390451      -0.526104  \n",
       "18188       -0.192370       -0.299580      -0.295317  \n",
       "18189       -0.672380       -0.411861      -0.465512  \n",
       "18190       -0.102144       -0.241372      -0.152149  \n",
       "18191        0.091437        0.021193      -0.014833  \n",
       "18192       -0.471531       -0.250229      -0.211129  \n",
       "18193       -0.333528       -0.136652      -0.177905  \n",
       "\n",
       "[18194 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = train_final[['']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(ada_new, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73771950808163722"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(ada, X, y, cv=10, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24929178,  0.2611465 ,  0.21973094,  0.29186603,  0.53333333,\n",
       "        1.        ,  0.43589744,  0.82051282,  0.57894737,  0.125     ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调参后10折的平均查准率 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores_roc1 = model_selection.cross_val_score(xgb_new, train_final.iloc[:, :-1], train_final.iloc[:, -1], cv=10, scoring='precision')\n",
    "print(\"调参后10折的平均查准率\",scores_roc1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=30,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, features, target, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[features].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics=\"auc\", early_stopping_rounds=early_stopping_rounds)\n",
    "#         print(\"最优估计器数目:\", cvresult.shape[0])\n",
    "        print(cvresult)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[features], dtrain[target],eval_metric=\"auc\")\n",
    "\n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[features])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[features])[:,1]\n",
    "\n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'goodyn'\n",
    "predictors = [x for x in train_final if x not in [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 确定最优估计器数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
      "0        0.636207      0.010789        0.659960       0.005870\n",
      "1        0.657966      0.012265        0.692113       0.004072\n",
      "2        0.670295      0.016034        0.708608       0.003480\n",
      "3        0.676063      0.017325        0.716819       0.005060\n",
      "4        0.680128      0.015371        0.723230       0.001677\n",
      "5        0.684810      0.017191        0.729796       0.002485\n",
      "6        0.689689      0.017489        0.734788       0.003784\n",
      "7        0.691045      0.016999        0.738508       0.003365\n",
      "8        0.693557      0.014890        0.741656       0.003280\n",
      "9        0.696892      0.014159        0.745305       0.002952\n",
      "10       0.698602      0.012998        0.748193       0.002721\n",
      "11       0.699229      0.012422        0.750302       0.002641\n",
      "12       0.700600      0.012366        0.751860       0.003307\n",
      "13       0.701629      0.012112        0.754750       0.002973\n",
      "14       0.702969      0.011143        0.756688       0.002408\n",
      "15       0.703773      0.011150        0.759356       0.002777\n",
      "16       0.705737      0.010417        0.761577       0.003204\n",
      "17       0.707388      0.009625        0.764077       0.003152\n",
      "18       0.709259      0.009973        0.766632       0.002308\n",
      "19       0.710648      0.010582        0.768699       0.002463\n",
      "20       0.713099      0.011022        0.771766       0.002289\n",
      "21       0.714390      0.011256        0.773701       0.001951\n",
      "22       0.715449      0.010852        0.775310       0.002257\n",
      "23       0.716167      0.011210        0.777058       0.002456\n",
      "24       0.718117      0.010167        0.780333       0.003780\n",
      "25       0.718898      0.010364        0.781444       0.004083\n",
      "26       0.719739      0.010742        0.783483       0.004359\n",
      "27       0.721575      0.010222        0.785499       0.004674\n",
      "28       0.723096      0.010235        0.786869       0.004537\n",
      "29       0.724377      0.010138        0.788828       0.004151\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.7745\n",
      "AUC Score (Train): 0.787007\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF7CAYAAAA9u5chAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25ab9a0c780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=30,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, train_final, predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth 和 min_weight 参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.46617, std: 0.44034, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.26626, std: 0.37435, params: {'max_depth': 3, 'min_child_weight': 6},\n",
       "  mean: 0.26299, std: 0.37533, params: {'max_depth': 3, 'min_child_weight': 11},\n",
       "  mean: 0.26730, std: 0.37450, params: {'max_depth': 3, 'min_child_weight': 16},\n",
       "  mean: 0.26755, std: 0.37453, params: {'max_depth': 3, 'min_child_weight': 21},\n",
       "  mean: 0.26506, std: 0.37499, params: {'max_depth': 3, 'min_child_weight': 26},\n",
       "  mean: 0.26776, std: 0.37416, params: {'max_depth': 3, 'min_child_weight': 31},\n",
       "  mean: 0.27172, std: 0.37324, params: {'max_depth': 3, 'min_child_weight': 36},\n",
       "  mean: 0.27523, std: 0.37222, params: {'max_depth': 3, 'min_child_weight': 41},\n",
       "  mean: 0.52508, std: 0.38861, params: {'max_depth': 3, 'min_child_weight': 46},\n",
       "  mean: 0.27977, std: 0.37120, params: {'max_depth': 3, 'min_child_weight': 51},\n",
       "  mean: 0.28100, std: 0.37161, params: {'max_depth': 3, 'min_child_weight': 56},\n",
       "  mean: 0.47439, std: 0.43459, params: {'max_depth': 3, 'min_child_weight': 61},\n",
       "  mean: 0.33020, std: 0.34666, params: {'max_depth': 3, 'min_child_weight': 66},\n",
       "  mean: 0.28298, std: 0.37103, params: {'max_depth': 3, 'min_child_weight': 71},\n",
       "  mean: 0.28011, std: 0.37193, params: {'max_depth': 3, 'min_child_weight': 76},\n",
       "  mean: 0.28708, std: 0.37014, params: {'max_depth': 3, 'min_child_weight': 81},\n",
       "  mean: 0.27944, std: 0.37173, params: {'max_depth': 3, 'min_child_weight': 86},\n",
       "  mean: 0.28002, std: 0.37127, params: {'max_depth': 3, 'min_child_weight': 91},\n",
       "  mean: 0.28353, std: 0.37075, params: {'max_depth': 3, 'min_child_weight': 96},\n",
       "  mean: 0.23399, std: 0.06690, params: {'max_depth': 8, 'min_child_weight': 1},\n",
       "  mean: 0.21354, std: 0.05044, params: {'max_depth': 8, 'min_child_weight': 6},\n",
       "  mean: 0.26227, std: 0.07691, params: {'max_depth': 8, 'min_child_weight': 11},\n",
       "  mean: 0.22896, std: 0.05694, params: {'max_depth': 8, 'min_child_weight': 16},\n",
       "  mean: 0.23392, std: 0.07058, params: {'max_depth': 8, 'min_child_weight': 21},\n",
       "  mean: 0.23252, std: 0.09918, params: {'max_depth': 8, 'min_child_weight': 26},\n",
       "  mean: 0.25020, std: 0.06373, params: {'max_depth': 8, 'min_child_weight': 31},\n",
       "  mean: 0.21548, std: 0.06877, params: {'max_depth': 8, 'min_child_weight': 36},\n",
       "  mean: 0.24930, std: 0.06528, params: {'max_depth': 8, 'min_child_weight': 41},\n",
       "  mean: 0.29773, std: 0.11380, params: {'max_depth': 8, 'min_child_weight': 46},\n",
       "  mean: 0.30612, std: 0.09623, params: {'max_depth': 8, 'min_child_weight': 51},\n",
       "  mean: 0.28563, std: 0.10928, params: {'max_depth': 8, 'min_child_weight': 56},\n",
       "  mean: 0.28707, std: 0.08420, params: {'max_depth': 8, 'min_child_weight': 61},\n",
       "  mean: 0.30500, std: 0.09944, params: {'max_depth': 8, 'min_child_weight': 66},\n",
       "  mean: 0.35015, std: 0.14390, params: {'max_depth': 8, 'min_child_weight': 71},\n",
       "  mean: 0.37205, std: 0.14511, params: {'max_depth': 8, 'min_child_weight': 76},\n",
       "  mean: 0.43779, std: 0.19301, params: {'max_depth': 8, 'min_child_weight': 81},\n",
       "  mean: 0.41263, std: 0.18352, params: {'max_depth': 8, 'min_child_weight': 86},\n",
       "  mean: 0.42035, std: 0.18350, params: {'max_depth': 8, 'min_child_weight': 91},\n",
       "  mean: 0.35807, std: 0.13344, params: {'max_depth': 8, 'min_child_weight': 96},\n",
       "  mean: 0.20619, std: 0.05721, params: {'max_depth': 13, 'min_child_weight': 1},\n",
       "  mean: 0.19917, std: 0.07227, params: {'max_depth': 13, 'min_child_weight': 6},\n",
       "  mean: 0.20660, std: 0.07216, params: {'max_depth': 13, 'min_child_weight': 11},\n",
       "  mean: 0.19990, std: 0.04749, params: {'max_depth': 13, 'min_child_weight': 16},\n",
       "  mean: 0.22970, std: 0.04289, params: {'max_depth': 13, 'min_child_weight': 21},\n",
       "  mean: 0.21769, std: 0.07429, params: {'max_depth': 13, 'min_child_weight': 26},\n",
       "  mean: 0.21721, std: 0.05425, params: {'max_depth': 13, 'min_child_weight': 31},\n",
       "  mean: 0.24674, std: 0.08074, params: {'max_depth': 13, 'min_child_weight': 36},\n",
       "  mean: 0.25916, std: 0.05629, params: {'max_depth': 13, 'min_child_weight': 41},\n",
       "  mean: 0.26874, std: 0.06708, params: {'max_depth': 13, 'min_child_weight': 46},\n",
       "  mean: 0.25391, std: 0.05180, params: {'max_depth': 13, 'min_child_weight': 51},\n",
       "  mean: 0.28857, std: 0.08774, params: {'max_depth': 13, 'min_child_weight': 56},\n",
       "  mean: 0.31140, std: 0.08606, params: {'max_depth': 13, 'min_child_weight': 61},\n",
       "  mean: 0.34220, std: 0.12158, params: {'max_depth': 13, 'min_child_weight': 66},\n",
       "  mean: 0.32259, std: 0.11667, params: {'max_depth': 13, 'min_child_weight': 71},\n",
       "  mean: 0.37164, std: 0.13962, params: {'max_depth': 13, 'min_child_weight': 76},\n",
       "  mean: 0.39438, std: 0.17210, params: {'max_depth': 13, 'min_child_weight': 81},\n",
       "  mean: 0.38577, std: 0.16643, params: {'max_depth': 13, 'min_child_weight': 86},\n",
       "  mean: 0.35638, std: 0.17396, params: {'max_depth': 13, 'min_child_weight': 91},\n",
       "  mean: 0.40168, std: 0.17729, params: {'max_depth': 13, 'min_child_weight': 96},\n",
       "  mean: 0.18463, std: 0.04323, params: {'max_depth': 18, 'min_child_weight': 1},\n",
       "  mean: 0.20542, std: 0.06070, params: {'max_depth': 18, 'min_child_weight': 6},\n",
       "  mean: 0.20185, std: 0.05938, params: {'max_depth': 18, 'min_child_weight': 11},\n",
       "  mean: 0.21553, std: 0.06532, params: {'max_depth': 18, 'min_child_weight': 16},\n",
       "  mean: 0.21455, std: 0.04111, params: {'max_depth': 18, 'min_child_weight': 21},\n",
       "  mean: 0.22015, std: 0.05242, params: {'max_depth': 18, 'min_child_weight': 26},\n",
       "  mean: 0.23250, std: 0.08438, params: {'max_depth': 18, 'min_child_weight': 31},\n",
       "  mean: 0.25178, std: 0.07367, params: {'max_depth': 18, 'min_child_weight': 36},\n",
       "  mean: 0.26781, std: 0.08551, params: {'max_depth': 18, 'min_child_weight': 41},\n",
       "  mean: 0.23583, std: 0.06559, params: {'max_depth': 18, 'min_child_weight': 46},\n",
       "  mean: 0.26599, std: 0.06128, params: {'max_depth': 18, 'min_child_weight': 51},\n",
       "  mean: 0.30476, std: 0.11355, params: {'max_depth': 18, 'min_child_weight': 56},\n",
       "  mean: 0.31208, std: 0.08703, params: {'max_depth': 18, 'min_child_weight': 61},\n",
       "  mean: 0.34086, std: 0.11843, params: {'max_depth': 18, 'min_child_weight': 66},\n",
       "  mean: 0.32259, std: 0.11667, params: {'max_depth': 18, 'min_child_weight': 71},\n",
       "  mean: 0.37164, std: 0.13962, params: {'max_depth': 18, 'min_child_weight': 76},\n",
       "  mean: 0.39438, std: 0.17210, params: {'max_depth': 18, 'min_child_weight': 81},\n",
       "  mean: 0.38577, std: 0.16643, params: {'max_depth': 18, 'min_child_weight': 86},\n",
       "  mean: 0.35638, std: 0.17396, params: {'max_depth': 18, 'min_child_weight': 91},\n",
       "  mean: 0.40168, std: 0.17729, params: {'max_depth': 18, 'min_child_weight': 96},\n",
       "  mean: 0.19140, std: 0.05166, params: {'max_depth': 23, 'min_child_weight': 1},\n",
       "  mean: 0.20280, std: 0.05125, params: {'max_depth': 23, 'min_child_weight': 6},\n",
       "  mean: 0.21994, std: 0.04952, params: {'max_depth': 23, 'min_child_weight': 11},\n",
       "  mean: 0.21877, std: 0.07568, params: {'max_depth': 23, 'min_child_weight': 16},\n",
       "  mean: 0.21727, std: 0.05202, params: {'max_depth': 23, 'min_child_weight': 21},\n",
       "  mean: 0.21020, std: 0.05166, params: {'max_depth': 23, 'min_child_weight': 26},\n",
       "  mean: 0.23142, std: 0.08320, params: {'max_depth': 23, 'min_child_weight': 31},\n",
       "  mean: 0.25430, std: 0.07448, params: {'max_depth': 23, 'min_child_weight': 36},\n",
       "  mean: 0.26781, std: 0.08551, params: {'max_depth': 23, 'min_child_weight': 41},\n",
       "  mean: 0.23583, std: 0.06559, params: {'max_depth': 23, 'min_child_weight': 46},\n",
       "  mean: 0.26599, std: 0.06128, params: {'max_depth': 23, 'min_child_weight': 51},\n",
       "  mean: 0.30476, std: 0.11355, params: {'max_depth': 23, 'min_child_weight': 56},\n",
       "  mean: 0.31208, std: 0.08703, params: {'max_depth': 23, 'min_child_weight': 61},\n",
       "  mean: 0.34086, std: 0.11843, params: {'max_depth': 23, 'min_child_weight': 66},\n",
       "  mean: 0.32259, std: 0.11667, params: {'max_depth': 23, 'min_child_weight': 71},\n",
       "  mean: 0.37164, std: 0.13962, params: {'max_depth': 23, 'min_child_weight': 76},\n",
       "  mean: 0.39438, std: 0.17210, params: {'max_depth': 23, 'min_child_weight': 81},\n",
       "  mean: 0.38577, std: 0.16643, params: {'max_depth': 23, 'min_child_weight': 86},\n",
       "  mean: 0.35638, std: 0.17396, params: {'max_depth': 23, 'min_child_weight': 91},\n",
       "  mean: 0.40168, std: 0.17729, params: {'max_depth': 23, 'min_child_weight': 96},\n",
       "  mean: 0.20384, std: 0.04866, params: {'max_depth': 28, 'min_child_weight': 1},\n",
       "  mean: 0.20978, std: 0.05240, params: {'max_depth': 28, 'min_child_weight': 6},\n",
       "  mean: 0.20856, std: 0.04069, params: {'max_depth': 28, 'min_child_weight': 11},\n",
       "  mean: 0.22096, std: 0.07974, params: {'max_depth': 28, 'min_child_weight': 16},\n",
       "  mean: 0.21678, std: 0.05130, params: {'max_depth': 28, 'min_child_weight': 21},\n",
       "  mean: 0.21064, std: 0.05244, params: {'max_depth': 28, 'min_child_weight': 26},\n",
       "  mean: 0.23142, std: 0.08320, params: {'max_depth': 28, 'min_child_weight': 31},\n",
       "  mean: 0.25430, std: 0.07448, params: {'max_depth': 28, 'min_child_weight': 36},\n",
       "  mean: 0.26781, std: 0.08551, params: {'max_depth': 28, 'min_child_weight': 41},\n",
       "  mean: 0.23583, std: 0.06559, params: {'max_depth': 28, 'min_child_weight': 46},\n",
       "  mean: 0.26599, std: 0.06128, params: {'max_depth': 28, 'min_child_weight': 51},\n",
       "  mean: 0.30476, std: 0.11355, params: {'max_depth': 28, 'min_child_weight': 56},\n",
       "  mean: 0.31208, std: 0.08703, params: {'max_depth': 28, 'min_child_weight': 61},\n",
       "  mean: 0.34086, std: 0.11843, params: {'max_depth': 28, 'min_child_weight': 66},\n",
       "  mean: 0.32259, std: 0.11667, params: {'max_depth': 28, 'min_child_weight': 71},\n",
       "  mean: 0.37164, std: 0.13962, params: {'max_depth': 28, 'min_child_weight': 76},\n",
       "  mean: 0.39438, std: 0.17210, params: {'max_depth': 28, 'min_child_weight': 81},\n",
       "  mean: 0.38577, std: 0.16643, params: {'max_depth': 28, 'min_child_weight': 86},\n",
       "  mean: 0.35638, std: 0.17396, params: {'max_depth': 28, 'min_child_weight': 91},\n",
       "  mean: 0.40168, std: 0.17729, params: {'max_depth': 28, 'min_child_weight': 96},\n",
       "  mean: 0.20963, std: 0.05122, params: {'max_depth': 33, 'min_child_weight': 1},\n",
       "  mean: 0.21536, std: 0.06458, params: {'max_depth': 33, 'min_child_weight': 6},\n",
       "  mean: 0.20826, std: 0.04019, params: {'max_depth': 33, 'min_child_weight': 11},\n",
       "  mean: 0.22096, std: 0.07974, params: {'max_depth': 33, 'min_child_weight': 16},\n",
       "  mean: 0.21563, std: 0.04914, params: {'max_depth': 33, 'min_child_weight': 21},\n",
       "  mean: 0.21064, std: 0.05244, params: {'max_depth': 33, 'min_child_weight': 26},\n",
       "  mean: 0.23142, std: 0.08320, params: {'max_depth': 33, 'min_child_weight': 31},\n",
       "  mean: 0.25430, std: 0.07448, params: {'max_depth': 33, 'min_child_weight': 36},\n",
       "  mean: 0.26781, std: 0.08551, params: {'max_depth': 33, 'min_child_weight': 41},\n",
       "  mean: 0.23583, std: 0.06559, params: {'max_depth': 33, 'min_child_weight': 46},\n",
       "  mean: 0.26599, std: 0.06128, params: {'max_depth': 33, 'min_child_weight': 51},\n",
       "  mean: 0.30476, std: 0.11355, params: {'max_depth': 33, 'min_child_weight': 56},\n",
       "  mean: 0.31208, std: 0.08703, params: {'max_depth': 33, 'min_child_weight': 61},\n",
       "  mean: 0.34086, std: 0.11843, params: {'max_depth': 33, 'min_child_weight': 66},\n",
       "  mean: 0.32259, std: 0.11667, params: {'max_depth': 33, 'min_child_weight': 71},\n",
       "  mean: 0.37164, std: 0.13962, params: {'max_depth': 33, 'min_child_weight': 76},\n",
       "  mean: 0.39438, std: 0.17210, params: {'max_depth': 33, 'min_child_weight': 81},\n",
       "  mean: 0.38577, std: 0.16643, params: {'max_depth': 33, 'min_child_weight': 86},\n",
       "  mean: 0.35638, std: 0.17396, params: {'max_depth': 33, 'min_child_weight': 91},\n",
       "  mean: 0.40168, std: 0.17729, params: {'max_depth': 33, 'min_child_weight': 96},\n",
       "  mean: 0.20963, std: 0.05122, params: {'max_depth': 38, 'min_child_weight': 1},\n",
       "  mean: 0.21536, std: 0.06458, params: {'max_depth': 38, 'min_child_weight': 6},\n",
       "  mean: 0.20826, std: 0.04019, params: {'max_depth': 38, 'min_child_weight': 11},\n",
       "  mean: 0.22096, std: 0.07974, params: {'max_depth': 38, 'min_child_weight': 16},\n",
       "  mean: 0.21563, std: 0.04914, params: {'max_depth': 38, 'min_child_weight': 21},\n",
       "  mean: 0.21064, std: 0.05244, params: {'max_depth': 38, 'min_child_weight': 26},\n",
       "  mean: 0.23142, std: 0.08320, params: {'max_depth': 38, 'min_child_weight': 31},\n",
       "  mean: 0.25430, std: 0.07448, params: {'max_depth': 38, 'min_child_weight': 36},\n",
       "  mean: 0.26781, std: 0.08551, params: {'max_depth': 38, 'min_child_weight': 41},\n",
       "  mean: 0.23583, std: 0.06559, params: {'max_depth': 38, 'min_child_weight': 46},\n",
       "  mean: 0.26599, std: 0.06128, params: {'max_depth': 38, 'min_child_weight': 51},\n",
       "  mean: 0.30476, std: 0.11355, params: {'max_depth': 38, 'min_child_weight': 56},\n",
       "  mean: 0.31208, std: 0.08703, params: {'max_depth': 38, 'min_child_weight': 61},\n",
       "  mean: 0.34086, std: 0.11843, params: {'max_depth': 38, 'min_child_weight': 66},\n",
       "  mean: 0.32259, std: 0.11667, params: {'max_depth': 38, 'min_child_weight': 71},\n",
       "  mean: 0.37164, std: 0.13962, params: {'max_depth': 38, 'min_child_weight': 76},\n",
       "  mean: 0.39438, std: 0.17210, params: {'max_depth': 38, 'min_child_weight': 81},\n",
       "  mean: 0.38577, std: 0.16643, params: {'max_depth': 38, 'min_child_weight': 86},\n",
       "  mean: 0.35638, std: 0.17396, params: {'max_depth': 38, 'min_child_weight': 91},\n",
       "  mean: 0.40168, std: 0.17729, params: {'max_depth': 38, 'min_child_weight': 96},\n",
       "  mean: 0.20990, std: 0.05168, params: {'max_depth': 43, 'min_child_weight': 1},\n",
       "  mean: 0.21536, std: 0.06458, params: {'max_depth': 43, 'min_child_weight': 6},\n",
       "  mean: 0.20826, std: 0.04019, params: {'max_depth': 43, 'min_child_weight': 11},\n",
       "  mean: 0.22096, std: 0.07974, params: {'max_depth': 43, 'min_child_weight': 16},\n",
       "  mean: 0.21563, std: 0.04914, params: {'max_depth': 43, 'min_child_weight': 21},\n",
       "  mean: 0.21064, std: 0.05244, params: {'max_depth': 43, 'min_child_weight': 26},\n",
       "  mean: 0.23142, std: 0.08320, params: {'max_depth': 43, 'min_child_weight': 31},\n",
       "  mean: 0.25430, std: 0.07448, params: {'max_depth': 43, 'min_child_weight': 36},\n",
       "  mean: 0.26781, std: 0.08551, params: {'max_depth': 43, 'min_child_weight': 41},\n",
       "  mean: 0.23583, std: 0.06559, params: {'max_depth': 43, 'min_child_weight': 46},\n",
       "  mean: 0.26599, std: 0.06128, params: {'max_depth': 43, 'min_child_weight': 51},\n",
       "  mean: 0.30476, std: 0.11355, params: {'max_depth': 43, 'min_child_weight': 56},\n",
       "  mean: 0.31208, std: 0.08703, params: {'max_depth': 43, 'min_child_weight': 61},\n",
       "  mean: 0.34086, std: 0.11843, params: {'max_depth': 43, 'min_child_weight': 66},\n",
       "  mean: 0.32259, std: 0.11667, params: {'max_depth': 43, 'min_child_weight': 71},\n",
       "  mean: 0.37164, std: 0.13962, params: {'max_depth': 43, 'min_child_weight': 76},\n",
       "  mean: 0.39438, std: 0.17210, params: {'max_depth': 43, 'min_child_weight': 81},\n",
       "  mean: 0.38577, std: 0.16643, params: {'max_depth': 43, 'min_child_weight': 86},\n",
       "  mean: 0.35638, std: 0.17396, params: {'max_depth': 43, 'min_child_weight': 91},\n",
       "  mean: 0.40168, std: 0.17729, params: {'max_depth': 43, 'min_child_weight': 96},\n",
       "  mean: 0.20990, std: 0.05168, params: {'max_depth': 48, 'min_child_weight': 1},\n",
       "  mean: 0.21536, std: 0.06458, params: {'max_depth': 48, 'min_child_weight': 6},\n",
       "  mean: 0.20826, std: 0.04019, params: {'max_depth': 48, 'min_child_weight': 11},\n",
       "  mean: 0.22096, std: 0.07974, params: {'max_depth': 48, 'min_child_weight': 16},\n",
       "  mean: 0.21563, std: 0.04914, params: {'max_depth': 48, 'min_child_weight': 21},\n",
       "  mean: 0.21064, std: 0.05244, params: {'max_depth': 48, 'min_child_weight': 26},\n",
       "  mean: 0.23142, std: 0.08320, params: {'max_depth': 48, 'min_child_weight': 31},\n",
       "  mean: 0.25430, std: 0.07448, params: {'max_depth': 48, 'min_child_weight': 36},\n",
       "  mean: 0.26781, std: 0.08551, params: {'max_depth': 48, 'min_child_weight': 41},\n",
       "  mean: 0.23583, std: 0.06559, params: {'max_depth': 48, 'min_child_weight': 46},\n",
       "  mean: 0.26599, std: 0.06128, params: {'max_depth': 48, 'min_child_weight': 51},\n",
       "  mean: 0.30476, std: 0.11355, params: {'max_depth': 48, 'min_child_weight': 56},\n",
       "  mean: 0.31208, std: 0.08703, params: {'max_depth': 48, 'min_child_weight': 61},\n",
       "  mean: 0.34086, std: 0.11843, params: {'max_depth': 48, 'min_child_weight': 66},\n",
       "  mean: 0.32259, std: 0.11667, params: {'max_depth': 48, 'min_child_weight': 71},\n",
       "  mean: 0.37164, std: 0.13962, params: {'max_depth': 48, 'min_child_weight': 76},\n",
       "  mean: 0.39438, std: 0.17210, params: {'max_depth': 48, 'min_child_weight': 81},\n",
       "  mean: 0.38577, std: 0.16643, params: {'max_depth': 48, 'min_child_weight': 86},\n",
       "  mean: 0.35638, std: 0.17396, params: {'max_depth': 48, 'min_child_weight': 91},\n",
       "  mean: 0.40168, std: 0.17729, params: {'max_depth': 48, 'min_child_weight': 96}],\n",
       " {'max_depth': 3, 'min_child_weight': 46},\n",
       " 0.52507793590860685)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,50,5),\n",
    " 'min_child_weight':range(1,100,5)\n",
    "}\n",
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=30,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=8,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "gsearch1 = GridSearchCV(estimator = xgb2, param_grid = param_test1, scoring='precision',n_jobs=8,iid=False, cv=5)\n",
    "gsearch1.fit(train_final[predictors],train_final[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_,     gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.08634, std: 0.10951, params: {'max_depth': 2, 'min_child_weight': 45},\n",
       "  mean: 0.08622, std: 0.10942, params: {'max_depth': 2, 'min_child_weight': 46},\n",
       "  mean: 0.08622, std: 0.10942, params: {'max_depth': 2, 'min_child_weight': 47},\n",
       "  mean: 0.47555, std: 0.43388, params: {'max_depth': 3, 'min_child_weight': 45},\n",
       "  mean: 0.52508, std: 0.38861, params: {'max_depth': 3, 'min_child_weight': 46},\n",
       "  mean: 0.27531, std: 0.37207, params: {'max_depth': 3, 'min_child_weight': 47},\n",
       "  mean: 0.32739, std: 0.17498, params: {'max_depth': 4, 'min_child_weight': 45},\n",
       "  mean: 0.29745, std: 0.21379, params: {'max_depth': 4, 'min_child_weight': 46},\n",
       "  mean: 0.49851, std: 0.29452, params: {'max_depth': 4, 'min_child_weight': 47}],\n",
       " {'max_depth': 3, 'min_child_weight': 46},\n",
       " 0.52507793590860685)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[2,3,4],\n",
    " 'min_child_weight':[45,46,47]\n",
    "}\n",
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=30,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=8,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "gsearch2 = GridSearchCV(estimator = xgb2, param_grid = param_test2, scoring='precision',n_jobs=8,iid=False, cv=5)\n",
    "gsearch2.fit(train_final[predictors],train_final[target])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_,     gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gamma参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.52508, std: 0.38861, params: {'gamma': 0.0},\n",
       "  mean: 0.52508, std: 0.38861, params: {'gamma': 0.5},\n",
       "  mean: 0.52508, std: 0.38861, params: {'gamma': 1.0},\n",
       "  mean: 0.52508, std: 0.38861, params: {'gamma': 1.5},\n",
       "  mean: 0.52629, std: 0.38762, params: {'gamma': 2.0},\n",
       "  mean: 0.52629, std: 0.38762, params: {'gamma': 2.5},\n",
       "  mean: 0.52629, std: 0.38762, params: {'gamma': 3.0},\n",
       "  mean: 0.52629, std: 0.38762, params: {'gamma': 3.5},\n",
       "  mean: 0.52629, std: 0.38762, params: {'gamma': 4.0},\n",
       "  mean: 0.52910, std: 0.38538, params: {'gamma': 4.5},\n",
       "  mean: 0.52916, std: 0.38533, params: {'gamma': 5.0},\n",
       "  mean: 0.32916, std: 0.34661, params: {'gamma': 5.5},\n",
       "  mean: 0.34524, std: 0.34470, params: {'gamma': 6.0},\n",
       "  mean: 0.34784, std: 0.34390, params: {'gamma': 6.5},\n",
       "  mean: 0.34784, std: 0.34390, params: {'gamma': 7.0},\n",
       "  mean: 0.34784, std: 0.34390, params: {'gamma': 7.5},\n",
       "  mean: 0.35078, std: 0.34257, params: {'gamma': 8.0},\n",
       "  mean: 0.47948, std: 0.43141, params: {'gamma': 8.5},\n",
       "  mean: 0.47993, std: 0.43114, params: {'gamma': 9.0},\n",
       "  mean: 0.27993, std: 0.37129, params: {'gamma': 9.5},\n",
       "  mean: 0.28019, std: 0.37121, params: {'gamma': 10.0},\n",
       "  mean: 0.28270, std: 0.37087, params: {'gamma': 10.5},\n",
       "  mean: 0.28041, std: 0.37155, params: {'gamma': 11.0},\n",
       "  mean: 0.48272, std: 0.42948, params: {'gamma': 11.5},\n",
       "  mean: 0.27729, std: 0.37168, params: {'gamma': 12.0},\n",
       "  mean: 0.28228, std: 0.37096, params: {'gamma': 12.5},\n",
       "  mean: 0.27708, std: 0.37175, params: {'gamma': 13.0},\n",
       "  mean: 0.27631, std: 0.37204, params: {'gamma': 13.5},\n",
       "  mean: 0.27901, std: 0.37129, params: {'gamma': 14.0},\n",
       "  mean: 0.27775, std: 0.37160, params: {'gamma': 14.5},\n",
       "  mean: 0.28231, std: 0.37077, params: {'gamma': 15.0},\n",
       "  mean: 0.28148, std: 0.37089, params: {'gamma': 15.5},\n",
       "  mean: 0.27470, std: 0.37216, params: {'gamma': 16.0},\n",
       "  mean: 0.27470, std: 0.37216, params: {'gamma': 16.5},\n",
       "  mean: 0.27438, std: 0.37223, params: {'gamma': 17.0},\n",
       "  mean: 0.27476, std: 0.37239, params: {'gamma': 17.5},\n",
       "  mean: 0.27576, std: 0.37215, params: {'gamma': 18.0},\n",
       "  mean: 0.27649, std: 0.37220, params: {'gamma': 18.5},\n",
       "  mean: 0.28135, std: 0.37083, params: {'gamma': 19.0},\n",
       "  mean: 0.28182, std: 0.37075, params: {'gamma': 19.5},\n",
       "  mean: 0.07827, std: 0.09732, params: {'gamma': 20.0},\n",
       "  mean: 0.27723, std: 0.37194, params: {'gamma': 20.5},\n",
       "  mean: 0.27862, std: 0.37154, params: {'gamma': 21.0},\n",
       "  mean: 0.08679, std: 0.10868, params: {'gamma': 21.5},\n",
       "  mean: 0.08342, std: 0.10370, params: {'gamma': 22.0},\n",
       "  mean: 0.08634, std: 0.11002, params: {'gamma': 22.5},\n",
       "  mean: 0.09064, std: 0.11349, params: {'gamma': 23.0},\n",
       "  mean: 0.08786, std: 0.10964, params: {'gamma': 23.5},\n",
       "  mean: 0.08897, std: 0.11132, params: {'gamma': 24.0},\n",
       "  mean: 0.07799, std: 0.09830, params: {'gamma': 24.5},\n",
       "  mean: 0.08030, std: 0.10256, params: {'gamma': 25.0},\n",
       "  mean: 0.08165, std: 0.10301, params: {'gamma': 25.5},\n",
       "  mean: 0.08443, std: 0.10743, params: {'gamma': 26.0},\n",
       "  mean: 0.08507, std: 0.10780, params: {'gamma': 26.5},\n",
       "  mean: 0.08346, std: 0.10659, params: {'gamma': 27.0},\n",
       "  mean: 0.07918, std: 0.09917, params: {'gamma': 27.5},\n",
       "  mean: 0.08444, std: 0.10691, params: {'gamma': 28.0},\n",
       "  mean: 0.08232, std: 0.10889, params: {'gamma': 28.5},\n",
       "  mean: 0.10694, std: 0.15351, params: {'gamma': 29.0},\n",
       "  mean: 0.10412, std: 0.13347, params: {'gamma': 29.5},\n",
       "  mean: 0.11570, std: 0.15272, params: {'gamma': 30.0},\n",
       "  mean: 0.11570, std: 0.15272, params: {'gamma': 30.5},\n",
       "  mean: 0.11484, std: 0.15124, params: {'gamma': 31.0},\n",
       "  mean: 0.11184, std: 0.14611, params: {'gamma': 31.5},\n",
       "  mean: 0.06476, std: 0.07948, params: {'gamma': 32.0},\n",
       "  mean: 0.12132, std: 0.18355, params: {'gamma': 32.5},\n",
       "  mean: 0.13836, std: 0.20341, params: {'gamma': 33.0},\n",
       "  mean: 0.13711, std: 0.20324, params: {'gamma': 33.5},\n",
       "  mean: 0.12003, std: 0.17305, params: {'gamma': 34.0},\n",
       "  mean: 0.03410, std: 0.06820, params: {'gamma': 34.5},\n",
       "  mean: 0.03410, std: 0.06820, params: {'gamma': 35.0},\n",
       "  mean: 0.02727, std: 0.05455, params: {'gamma': 35.5},\n",
       "  mean: 0.02906, std: 0.05812, params: {'gamma': 36.0},\n",
       "  mean: 0.03153, std: 0.06307, params: {'gamma': 36.5},\n",
       "  mean: 0.15005, std: 0.22178, params: {'gamma': 37.0},\n",
       "  mean: 0.15312, std: 0.22226, params: {'gamma': 37.5},\n",
       "  mean: 0.03393, std: 0.06786, params: {'gamma': 38.0},\n",
       "  mean: 0.03393, std: 0.06786, params: {'gamma': 38.5},\n",
       "  mean: 0.02368, std: 0.04736, params: {'gamma': 39.0},\n",
       "  mean: 0.02673, std: 0.05347, params: {'gamma': 39.5},\n",
       "  mean: 0.03194, std: 0.06388, params: {'gamma': 40.0},\n",
       "  mean: 0.02444, std: 0.04889, params: {'gamma': 40.5},\n",
       "  mean: 0.02650, std: 0.05300, params: {'gamma': 41.0},\n",
       "  mean: 0.02584, std: 0.05169, params: {'gamma': 41.5},\n",
       "  mean: 0.02190, std: 0.04380, params: {'gamma': 42.0},\n",
       "  mean: 0.02190, std: 0.04380, params: {'gamma': 42.5},\n",
       "  mean: 0.02391, std: 0.04783, params: {'gamma': 43.0},\n",
       "  mean: 0.02751, std: 0.05501, params: {'gamma': 43.5},\n",
       "  mean: 0.02751, std: 0.05501, params: {'gamma': 44.0},\n",
       "  mean: 0.02732, std: 0.05464, params: {'gamma': 44.5},\n",
       "  mean: 0.02732, std: 0.05464, params: {'gamma': 45.0},\n",
       "  mean: 0.02493, std: 0.04985, params: {'gamma': 45.5},\n",
       "  mean: 0.02493, std: 0.04985, params: {'gamma': 46.0},\n",
       "  mean: 0.02379, std: 0.04759, params: {'gamma': 46.5},\n",
       "  mean: 0.02089, std: 0.04177, params: {'gamma': 47.0},\n",
       "  mean: 0.01980, std: 0.03960, params: {'gamma': 47.5},\n",
       "  mean: 0.02089, std: 0.04177, params: {'gamma': 48.0},\n",
       "  mean: 0.02089, std: 0.04177, params: {'gamma': 48.5},\n",
       "  mean: 0.02470, std: 0.04940, params: {'gamma': 49.0},\n",
       "  mean: 0.03178, std: 0.06357, params: {'gamma': 49.5}],\n",
       " {'gamma': 5.0},\n",
       " 0.52915809523809521)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,500,5)]\n",
    "}\n",
    "xgb3 = XGBClassifier( \n",
    "    learning_rate =0.1, \n",
    "    n_estimators=30, max_depth=3, \n",
    "    min_child_weight=46, gamma=0, \n",
    "    subsample=0.8, colsample_bytree=0.8, \n",
    "    objective= 'binary:logistic', \n",
    "    nthread=8, \n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "gsearch3 = GridSearchCV(estimator=xgb3, param_grid = param_test3, scoring='precision',n_jobs=8,iid=False, cv=5)\n",
    "gsearch3.fit(train_final[predictors],train_final[target])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_,     gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
      "0        0.597012      0.012475        0.609723       0.008619\n",
      "1        0.625278      0.016617        0.640217       0.005724\n",
      "2        0.633781      0.015535        0.652382       0.004146\n",
      "3        0.641437      0.012855        0.660844       0.002437\n",
      "4        0.643666      0.014788        0.664351       0.003462\n",
      "5        0.646613      0.015690        0.667147       0.001496\n",
      "6        0.649437      0.016063        0.670110       0.002795\n",
      "7        0.652502      0.014199        0.672150       0.002119\n",
      "8        0.653586      0.013683        0.673735       0.002896\n",
      "9        0.655397      0.012009        0.676009       0.002533\n",
      "10       0.656287      0.012353        0.676502       0.003134\n",
      "11       0.657134      0.012126        0.677071       0.003487\n",
      "12       0.657599      0.011784        0.678997       0.003664\n",
      "13       0.659421      0.010911        0.681231       0.002774\n",
      "14       0.660279      0.010819        0.681946       0.002217\n",
      "15       0.660779      0.010467        0.682561       0.002417\n",
      "16       0.661451      0.011319        0.683886       0.001705\n",
      "17       0.662538      0.010398        0.685343       0.002961\n",
      "18       0.663164      0.010501        0.686511       0.002457\n",
      "19       0.663970      0.009914        0.687635       0.002734\n",
      "20       0.664706      0.009414        0.688381       0.002780\n",
      "21       0.665684      0.009384        0.689902       0.002671\n",
      "22       0.666788      0.009385        0.690886       0.002976\n",
      "23       0.667084      0.009590        0.691764       0.002354\n",
      "24       0.668304      0.008842        0.693035       0.002892\n",
      "25       0.668802      0.008743        0.693930       0.003000\n",
      "26       0.669291      0.008609        0.694881       0.003290\n",
      "27       0.669873      0.008386        0.696180       0.003197\n",
      "28       0.670634      0.009109        0.697197       0.003214\n",
      "29       0.671571      0.009179        0.698281       0.002747\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.7512\n",
      "AUC Score (Train): 0.700670\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAF7CAYAAAA61YtxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XuYJVV57/Hvj+E2GFGEBkQDAwHB\nIEE8LRFQuXiUBDCiEVBDgBAyD0EQ9eA5JBiUKDAKKgomMqAOCsdbBJMAgZDDMENAcmgyDF6AyGUg\nOmIaEUZhQBjf/FHVsunp3bt6uqpW1a7f53n62buqu6refnvvt2uvtWqVIgIzM+uW9VIHYGZm9XPx\nNzPrIBd/M7MOcvE3M+sgF38zsw5y8Tcz6yAXf5sVSTdIWinpnvzr1FnubwtJV5cV3zocf07+e/xI\n0pP589MSxXKppJelOLYNv/VTB2BDYX5EXFnSvn4D2LOkfc1YRKwBdpS0H3BuRIymigV4LbBhwuPb\nEPOZv1UiP4NeIOl7kn4g6a96vndovv7e/PH38/VfBW4ANuv5JHFa/r1Fkk7s2cfDkublz2+QdIyk\nmyX9Z++nD0nvk3RHvq/PSpozi9/pLklnSXpA0tH549n591ZIOknSbfn6t/dsd0K+7f2SLpP0gnz9\nMZIulHSRpPvy3+P5ecz3AC8Brs5j/4ee/V2br7tP0lckbdSThw9IWp5/GjuuZ5sRSV/Lt7lP0jsK\n/J22knRlHvsKSSesa+6sgSLCX/5a5y+yYn3IFOv/FDgfEDAXuBXYN//epsCc/PnrgDt7tpsHPDzF\n/hYBJ/YsPwzM64nhDuClwIuB1cBGwBuAbwEbkH3K/Xvg6IK/137A2KR19wMfAhYAS4Bdgbvz760A\nLs9/1z2AnwBzgH2BO4EXkZ1sfRn4ZL7NMcCTwOH58tXAsT3HWwG8YorYNssf1wOuA47oycONwPOB\nUeChnm2uAs7M/x7r9exjur/Th4ELevaxfurXm7/K+/KZv5Xhb/Ozw7skvTVfdxDwVrLCt4ysKO+Y\nf287sjPaO8mK+kgJMZweET+MiB8Df0RW4A4C9gK+A3wXeCWwwyyOIeBSsoL9JeBxsn8yvTGsjohl\n+c++FDgEuCwiHomIXwELyf6xTLgmIr6ePz8NuKVAHCdJ+g7wPbImst78fSwifg7cBWwFIGku2T/C\nMyLzq4j4Wf7z0/2d/gV4u6RPSPofEfFMgdisJdzmb2X481i7zX994LSIuGSKn/8C8DcR8cW86Was\n53v9JpsaNAnVrwtTRFwOIGn9/DhnDNh2JtZMeuxnI+AXZGf/v+pZH8Ave5Z74142aR9r/c6SDgYO\nA/aJiFWSFhWIeUOyf0ZTxdz37xQR/yrplcDhwJcl/WNE/J8Cx7MW8Jm/VWUpcLykTQEkbZAXY4At\ngbskbQicOGm7nwKbSto23075+nGyTwxI+iNg84IxHCXpxfl26020j1dk/fw4fwzcFRE/JWseeoek\nTSWtBxwPFO0cHwd2z/c5kYctgR/lhX934IBBO4mIx4DvAydP7EvSC/Nv9/07SXp+RDwUEZ8B3gMc\nWDBuawEXf6vKBcBtwB2S7iJrUpgo2B8Gvk7WTv9o70YR8Qvgg8BNku4FJjogLwJ+T9JNZE05/1Eg\nhsvJ2thvkvQfZE0/L59ug7wD9B7gMuAVmtlQz2vzbY8E3pn/Pn8PXAHcDtwNrALOLbi/DwIflnQf\nz/7DuAKYK+l+4FPAtwvu653AwZJWAPcCb8zXT/d3+ou88/pe4OPA+wsey1pAEZ7S2Wy28qJ6SER8\nN3UsZkX4zN/MrIN85m9m1kE+8zcz6yAXfzOzDnLxNzProMZe5LXFFlvEvHnzUodhZtYqt91228MR\nMfCq+cYW/3nz5jE2Njb4B83M7NckPVDk59zsY2bWQZUV/3x622ckzZO0p6Slkr4tqejVjWZmVpFK\nin8+WdchwM35qouAIyNiL2BPSXtXcVwzMyum9OKfT0B1PnAS2WyGm5HNJvhjSR8jm2Hw1X22nS9p\nTNLY+Ph42aGZmVmuijP/+cDiiJiYeEvAxmQTSH2VbMKsKUXEwogYjYjRkZEypng3M7OpVFH83wwc\nKukGsptn/A3ZTIpnk81seBDPNgeZmVkCpQ/1jIhDJp7n/wCOIbt70jfI7oB0XUTcWvZxzcysuErH\n+UfEfvnTFfRp5zczs/o19iKvmZh36lWl73PFgoNL36eZWVP4Ii8zsw5y8Tcz6yAXfzOzDnLxNzPr\nIBd/M7MOcvE3M+sgF38zsw5y8Tcz6yAXfzOzDnLxNzPrIBd/M7MOcvE3M+sgF38zsw5y8Tcz6yAX\nfzOzDhqK+fzbouz7DvieA2a2rnzmb2bWQS7+ZmYdVFmzj6RrgI2AjYE/A94OvAN4CHgsIt5S1bHN\nzGx6lRX/iPg9AEmnA/vkqxdExKKqjmlmZsVU1uwj6WBJY8BRwD8CjwInSrpR0nv6bDNf0piksfHx\n8apCMzPrvMqKf0RcFRGjwHuAv42I8/LlNwJHStp5im0WRsRoRIyOjIxUFZqZWefV0eH7KPBkz/Ka\n/PHnNRzbzMymUEmbv6TtgUVkRX8V8F5JpwIH5j9ybkSsrOLYZmY2WCXFPyLuB/adtHpB/mVmZol5\nnL+ZWQe5+JuZdZCLv5lZB7n4m5l1kIu/mVkHufibmXWQi7+ZWQe5+JuZddDA4i9pjqQjJL07X96l\n+rDMzKxKRc78vwyMAkfny+dVF46ZmdWhSPHfJiI+ADyeL29YYTxmZlaDIsV/taRRICTtUXAbMzNr\nsCITux0PnANsDZwBnFBpRGZmVrmBxT8iHpD0joj4VR0BmZlZ9YqM9vkksLyGWMzMrCZF2u9HI2K3\nyiMxM7PaFCn+d0jaq/JIzMysNkU6fPcBjpO0EhAQEbFDtWGZmVmVinT47lFHIGZmVp+BxV/SXGA+\nsCOwDLgkItZUHZiZmVWnSJv/JcCLgCuBHYALi+xY0jWSFkv6tqRXSNpT0tJ8+dxZxGxmZrNUpM1/\nJCIOz59fK2lxkR1HxO8BSDqdrN/gBODNEfFg/k9g74i4eZ2iNjOzWSly5r9G0g4AkrYHNimyY0kH\nSxoDjiL71LAG+LGkj5HND/TqKbaZL2lM0tj4+HjR38HMzGaoyJn/+4FLJW0JPAacXGTHEXEVcJWk\ng4DPARsDF+TPf8gU/3giYiGwEGB0dDSKHMfMzGauyGifO4C9Z3GMR4EnyM72zwYeAM4CTp/FPs3M\nbBaKjPY5KSLO71l+d0R8dsA22wOLgCeBVcB7gZ2Bb+TrrouIW2cRt5mZzUKRZp8/BM7vWT4MmLb4\nR8T9wL6TVv+IKdr5zcysfkU6fDeQtCmApI2A51cbkpmZVa3Imf/ZwL9Juh34HeDT1YZkZmZVK9Lh\ne6WkG4GXAQ9GxE+qD8vMzKpU6JaMEfEYcB8wKsn38DUza7lpi7+kq/PHOcDVZJ29F9QQl5mZVWjQ\nmf/EWf6bgcsj4hiy+X3MzKzFBrX5z8mv7D0ReOfEumpDMjOzqg068/84cC3wzYiYmGznl9WGZGZm\nVZv2zD8i/gn4p0nrDqw0IjMzq1yh0T5mZjZcXPzNzDrIxd/MrINc/M3MOsjF38ysgwYWf0lzJB0h\n6d358i7Vh2VmZlUqcub/ZWAUODpfPq+6cMzMrA5FpnTeJiLeJWlxvuyJ3YbYvFOvKn2fKxYcXPo+\nzWx2ipz5r5Y0CoSkPQpuY2ZmDVbkzP944Bxga+AM4IRKIzIzs8oVuZnLA8DhM9mppE2AhcBLgE2A\no8gmhnsH8BDwWES8ZcbRmplZKYqM9jlp0vK7B20TEU8AH4qI/YHP8+ynhQURsZ8Lv5lZWkXa7/9w\n0vJhRXYcEffmT7chuwvYo8CJkm6U9J7iIZqZWdmKtPlvIGnTiFglaSPg+UV3LulQYA/g7RHxNHCe\npI2BpZKujYi7J/38fGA+wLbbblv4lzAzs5kpcuZ/NvBvkr4C/DtwYZEdSzqW7FPCYXnhn7Amf/z5\n5G0iYmFEjEbE6MjISJHDmJnZOijS4XulpBuBlwEPRsRPBm2TDw29CLgJ+GdJvwSuBybuBXBuRKxc\n97DNzGw2BhZ/SesBOwJzgZ0l7RwRS6fbJiLGmPp2jwvWKUozMytVkTb/a4AngJ/lywFMW/zNzKzZ\nihT/jSLiTZVHYmZmtSlS/G+R9MfAkokVEfFgdSGZmVnVihT/PfOvY/PlAA6oLCIzM6tckdE++9cR\niJmZ1afIaJ8DgZPI5ugBICJ85m9m1mJFL/L6K7KhnmcAyyqNyMzMKlek+K+KiGXA6ohYAuxWcUxm\nZlaxIsX/kfxCr+WSrgBeUHFMZmZWsSIdvm8DkHQK8DrgO1UHZWZm1Soyn/9OABGxJiJuAF5UdVBm\nZlatIuP8L+S54/onL5vVri03mm9LnNY9M7oZu6TNgM0risXMzGrS98xf0nHAacBWku4DBDwOfKam\n2MzMrCJ9i39EXAxcLGmxr/I1MxsuRZp93psP9TQzsyFRpKgfDSyvOhAzM6tPkeI/GhG+qtfMbIgU\nKf53SNqr8kjMzKw2Rcb57wMcJ2kl2YifiIgdqg3LzMyqVGR6hz1mulNJmwALgZeQTQV9FNmcQOcC\nGwA3RcQpM92vmZmVo8h8/nOB+cCOZNM5XxIRa6bbJiKekPShiLhX0nzgBGA/4M0R8aCkpZL2joib\nZ/8rmJnZTBVp87+EbD6fK4EdyKZ3GCgi7s2fbgM8AqwBfizpY8CGwKsnbyNpvqQxSWPj4+NFDmNm\nZuugSJv/SEQcnj+/VtLiojuXdCiwB9knhyOAC4DPAT9kin88EbGQrLmI0dHRKHocMzObmSJn/msk\n7QAgaXt6buc4HUnHAocBh0XET8jO9s8GbgcOAtzkY2aWSJEz//cDl0raEngMOHnQBpJGgYuAm4B/\nlvRLsrP/bwBPAtdFxK3rHLWZmc1KkdE+dwB7z2SnETEGzJniW2u185uZWf2KjPZ5J3A62RDNlcCf\nR8T3qg7MzOrj+w50T5Fmn1OA10TEY5J2Ieu0/Z/VhmVmZlUq0uG7kmyYJhFxF8X+YZiZWYMVKeRr\ngJsljZFN77CbpC8ARMSxVQZnZmbVKFL8PzVpeVEFcZiZWY2KFP+NyUbprMezE7v9daVRmZlZpYoU\n/3OA9wLPVByLmZnVpEjxv4ZsNs7byc/8gaVVBmVmZtUqUvz3BY4EflFxLGZmVpMixf/nwHXA3Tx7\n5n9AlUGZmVm1ikzv4Au6zMyGzLTFX9J7I+K8QevMzOrgaSjKM+gK38Ml/aakbfOv7YDDB2xjZmYN\nN6jZ5+Vkd/JSz7pdqgvHzMzqMKj43x4Rz+ncncmdvMzMrJkGNfucUHCdmZm1yLTFPyLuLLLOzMza\npciUzmZmNmRc/M3MOqiS4i9pY0knSloh6Zh83Ycl3SXpBkl/X8VxzcysmKruyrUV8BRw2aT1CyJi\nUUXHNDOzgio584+IByLiIuDpntWPAidKulHSe6o4rpmZFTOw+Et6g6TbJd2ZL390XQ4UEedFxCjw\nRuBISTtPcaz5ksYkjY2Pj6/LYczMrIAiZ/5nAm8AHsqXf3eWx1yTP/588jciYmFEjEbE6MjIyCwP\nY2Zm/RRp838qIn4qKfLl3xi0gaSXAt8CtgGeknQA8H3gwPxHzo2IlesSsJmZzV6R4n+lpCuB7SV9\nC7h+0AYR8UNgdIpvLZhhfGZmVoEi8/mfI+lqYFfg3oi4rfqwzMysSgOLv6SdgEMj4swa4jEzsxoU\n6fD9GrCi4jjMzKxGRYr/Q8BXqg7EzMzqU6TDdznwTUlXTKyIiC9VF5KZmVWtSPF/Ergd2L7iWMzM\nrCZFRvucUUcgZmbDog03mi8y2mcxEL3rJt/a0czM2qVIs88xPc9fBby+mlDMzKwuRZp9HuhZfEDS\nYRXGY2ZmNSjS7PNFnm32eR7wwkojMjOzyhVp9lnU8/xxspE/ZmbWYkWK/8qI+MHEQj7dww+m+Xkz\nM2u4Ilf4Xjhg2czMWmZGt3GUtBmweUWxmJlZTfo2+0g6DjgN2ErSfYDI2vw/U1NsZmZWkb7FPyIu\nBi6WtDgi9q8xJjMzq1iRZp/3Vh6FmZnVqshon60lnQXMnVjh6R3MzNqtyJn/2cAHyYr/GcCySiMy\nM7PKFSn+qyJiGbA6IpYAuw3aQNLGkk6UtELSMfm6PSUtlfRtSefOLmwzM5uNIsX/EUnrAcvzG7q8\noMA2WwFPAZf1rLsIODIi9gL2lLT3jKM1M7NSDCz+EfG2iPgVcArwaeCgAts8EBEXAU/Dr68PWAP8\nWNLHgA2BV0/eTtJ8SWOSxsbHx2f2m5iZWWEDi7+kOZKOAI6PiBuAkXU4joCNgQuAr/LcTwS/FhEL\nI2I0IkZHRtblMGZmVkSRZp8vA6PA0fnyeTM9SEQ8Qna2fzbZxHAHATfPdD9mZlaOIkM9t4mId+V3\n9IKsiE9L0kuBbwHbAE9JOgCYD3yD7J7A10XEresYs5mZzVKR4r9a0igQkvagWD/BD8k+LUy2Vju/\nmZnVr0jxPx44B9iabJz/CZVGZGZmlSt6G8fDa4jFzMxqMm0TjqST8se31ROOmZnVYVD7/VvzxxOr\nDsTMzOozo5u5mJnZcBjU5r9XfiOXF/fc0CUiYofqQzMzs6pMW/wjYu503zczs3Zys4+ZWQe5+JuZ\ndZCLv5lZB7n4m5l1kIu/mVkHufibmXWQi7+ZWQe5+JuZdZCLv5lZB7n4m5l1kIu/mVkHufibmXWQ\ni7+ZWQfVXvwlPSnphvzrrYO3MDOzshW5gXvZHoqI/RIc18zMcimafZ6RtFTS5ZK27/2GpPmSxiSN\njY+PJwjNzKwbai/+EbFjRLweuBQ4a9L3FkbEaESMjoyM1B2amVlnpOzwFfCzhMc3M+usWtv8JW0J\nfBN4Cvgv4N11Ht/MzDK1Fv+I+C/gdXUe08zM1uZx/mZmHeTib2bWQS7+ZmYd5OJvZtZBLv5mZh3k\n4m9m1kEu/mZmHeTib2bWQS7+ZmYd5OJvZtZBLv5mZh3k4m9m1kEu/mZmHeTib2bWQS7+ZmYd5OJv\nZtZBLv5mZh3k4m9m1kEu/mZmHVRb8Zc0R9JnJS2RdLOk3eo6tpmZPVedZ/5vB9aPiH2BDwKfqPHY\nZmbWQxFRz4GkTwP/D1gJ/BXwyojYbtLPzAfm54s7A3eXHMYWwMMl77MKjrNcjrM8bYgRuh3ndhEx\nMuiH6iz+nwGeD9wDnAN8PyJ2rOXgz8YwFhGjdR5zXTjOcjnO8rQhRnCcRdTZ7DMGREScCbwKuKvG\nY5uZWY/1azzWV4A3SVoKPA0cX+OxzcysR23FPyKeBo6s63h9LEx8/KIcZ7kcZ3naECM4zoFqa/M3\nM7Pm8EVeZmYd5OJvZtZBLv5mZh3k4m9m1kF1DvWslaRt+30vIh6sM5bpSPoiMGWve0QcW3M4fTmf\n5XI+y+V8ztzQFn/gkvzxVcBtgIBXALcCB6UKagqL8scLgBPz528GnkgSTX/OZ7mcz3I5nzMVEUP9\nBSzpeb49cFnqmPrEecOk5WtTx+R8Op/O5/Dmc5jP/CeskbRtZB/9xskmjGuiMUkXA7eQvWg3TBxP\nP85nuZzPcjmfBQ39RV6S9gA+A7wY+CWwICK+lDaqqUk6ENgdeAi4PCJ+kTiktTif5XI+y+V8zuD4\nw17820LSThHxg37LNjPOZ7mcz3I1IZ9DP9RT0pnTLTfIhQOWG8H5LJfzWS7ns7ihL/7AXpOWX5sk\nihmQtBmweeo4+nA+y+V8lsv5LGhoO3wlvR7YH5gn6fR89eY07HeWdBxwGrCVpPvIhqg9TtZu2RjO\nZ7mcz3I5n+sQy7C2+UvaEdgHOBVYkK9+ArguIh5NFlgfkhZHxP6p4+jH+SyX81ku53MdYhjW4j9B\n0qci4n2p4xhE0u4RsTx1HIM4n+VyPsvlfBY39G3+vS8ESS9JGcsAm0N2mbqkiyTtkzqgqTif5XI+\ny+V8Fjf0xV/SZfnjnwHXSGrkKAXgQ/njR4HFwFkJY+nL+SyX81ku57O4oS/+wNb54zvJ5v3YJWEs\n01kjaRNg64j4v/SZ/KkBnM9yOZ/lcj4LalRPeEVC0inA9yLiaUlKHVAf/x+4E/jzfHmDhLFMx/ks\nl/NZLuezoC50+P428Fbg/IhYJekvI6KpH1kV+R9E0khEjKeOaTLns1zOZ7mczxkcf9iLfz+Sjmrq\nnB+9JF0fEQekjmMQ57Nczme5nM+1daHNv59jUgdQUFM/tk52TOoACnI+y+V8lqu2fHa5+LflRduW\nj2bOZ7mcz3I5n5N0ufi35UXbFs5nuZzPcjmfk3S5+LdFW85Y2sL5LJfzWS43+9SgLS/aRakDKMj5\nLJfzWS7nc5JOFf/ey71TT6o0maQD8sfnXO4dEZdMv2U6zme5nM9yOZ/TG/ri78u9y+V8lsv5LJfz\nWdzQF398uXfZnM9yOZ/lcj4L8vQOzZH8cu+CnM9yOZ/lcj4LGvorfH25d7mcz3I5n+VyPmdw/A4U\n//Uj4pnUcQwi6X3AlyPi4dSxTMf5LJfzWS7ns7gutPnfLenTkl6ZOpABNgKulfQtSYdKamqTnPNZ\nLuezXM5nQV04898QOBh4F/BS4FLgixHxRNLA+sg/tv5v4E3AJ4BPRoP+SM5nuZzPcjmfMzh2g/5u\nlcrH0Z5IdpPnJ4BjIuKWtFE9S9LGwNvIJqDaFPg8sBOwaUQcnzC0KTmf5XI+y+V8FhARQ/0F/CXw\nfeBy4PfJmrq2AZamjm1SnCuA84HdJ61fkjo259P5dD6HL59NbbcrUwAHRMRDPetWSropVUB97BIR\nT06xfn7tkUzP+SyX81ku57OgoW/2kTQH2APYZGJdRCxNF9HUJB0InMRz42zcTTKcz3I5n+VyPovr\nwpn/N4A5wKuB7wBPA417MQBnA38K/A1wKvAHacPpy/ksl/NZLuezoC4M9dwyIt4C3EU2CqCpH3VW\nRcQyYHVELAF2Sx1QH85nuZzPcjmfBXWh+E/88Z8GdiXr/GmiRyStByyXdAXwgtQB9eF8lsv5LJfz\nWVTqXu8aetUPIfsn91rgBuDk1DENiHcOsB+weepYnE/n0/kc3nwOfYdv00natt/3IuLBOmMZBs5n\nuZzPcjUpn0Nb/CV9kT7tfRFxbM3h9CVpcf70VcBtZHccegVwa0QclCywSZzPcjmf5XI+Z26YR/ss\nyh8vILvSD+DNZFf7NUbkdxiStCTyoV6Stie7yUOTLMofnc9yLMofnc9yLMofnc+Chrb4R9aDjqSf\nTjwHlki6NmFY01kjadv8o984sHPqgHo5n+VyPsvlfM7c0Bb/HmOSLgZuAXYANkwcTz//C7hM0ouB\nXwILEsfTT1vy+X6czzI5n+VK/n4f2jb/XvnVdLsDDwGXR8QvEofUas5nuZzPcjmfxQz9OH9JrwFe\nBqwmu7Vb414IknaVdK2k+yX9h6R/kPRbqeOaSkvy+Zb8cTtJl0m6QFIjx6U7n+VqST4b8X4f6uIv\n6ePAx8hu5hzARyR9MG1UU7qQ7GPfcrILU84CPpc0oim0KJ8n54+fAP4OuB74bLpwpuZ8lqtF+WzE\n+32oiz+wT0TsSza3x41kl3u/MW1IU3omIhYDHwFOiWze8Sa2VbYlnxO2iIgrIuJyYMvUwUzB+SxX\nW/LZiPf7sBf/ZyS9BPggcDzwm8DctCFN6buS/hZ4MbBT3mHVxAto2pLPvSTdx3Mv7d84VTDTcD7L\n1ZZ8NuL9PtQdvpL2BBYCz5C9CDYA5kfEDSnjmiyf4+PtwN5kF33cCnw1GnYj6rbkcyqSRiJiPHUc\nvZzPcrUln015vw918Z8g6YVkv+vPUscyFUkbAS+PiNslbQa8DviXaO59Rxudz+lIuj4aNg+981mu\npuezKe/3oR7nr+zmyPsA/wh8TtJq4P0R8eO0ka3l64Ak3QO8Bvge8EfAEUmjmkTSTmRXIv42MC7p\nW8D50a4zCKUOYEKLXp/TaVI+2/L6bMT7fdjb/C8CtibrALoQ+AxwXtKIprZlRPwB2V19vhYRfwaM\nJI5pKgvJLp9/E9lViQL+ImlEM9ekQtCW1+d0mpTPtrw+G/F+H/bi/2REfAR4LCL+KSK+DWyaOqgp\nKJ/fYzdgd0nPA34jcUxTUUTcmJ+ZbhERnwbekDqoFmvL67Mt2vL6bMT7faibfcgumwb4UM+6Jvb+\nnwl8Pn/cDvg+8PGkEU3tAUkfITuj+lHqYNZRY5opaM/rczpNymdbXp+NeL93osO3l6R5EbEidRxt\nJGl9srbJucCXIuIJSVtFxE8Sh1aYpKMj4pLUcfTTttdnk/I5DK/POg17s89aJt5Ykq5PHMq0JC1K\nHcNkEfFMRFwSEZ+bGJkw8cZqQT4/D9CUQtVPU1+fkt4g6XZJd+bLH4Vm5bPlr89FdR9z2Jt9ptOY\nj6uSjpq8imz4V5s0Ip9T5BKy2PaqO5ZZakQ+e5xJ1n7+d/ny7yaMZV00Jp9Neb93ufg3qb3rDOBS\nsotTJmyUKJZ11ZR8ngF8kbXf7E28InU6TcnnhKci4qeSJuJq4oCE6TQpn414v3e5+DfJuWQjPz4/\nsULSIQnjabM7I+KvJ6+UtF+CWIbJlZKuBLbPx883uhml4Rrxfu9y8W/Mx0DgYmCrSesOTRHILDQi\nn9PcB/WwWgOZvUbkc0JEnCPparJZKO+NiNtSxzRDTcpnI97vnevw7bEodQATIuKp/HZuvet+BM3v\nqOqxKHUAvSTNlXSypPMlHQs08lL/aSxKHUAvSTtFxPci4usRcVt+NW2bLEodwISmvN87V/zbMuqj\nR5POWNbS4HxeAmwGXEl2O78L04YztTaMoslNzp/zWY3a3u9D2+wzRKM+GtFR1cJ8jkTEh/Pn10pa\nnDKYabRuFE0+GdnmqePoo3X5nKS29/vQFn+GZ9RHU7Qtn2sk7RAR9+WX0m+SOqA+Gj2KRtJxwGnA\nVvmc/gIeJ5uHqIkanc8mGebiPyyjPprS7NO2fL4fuFTSCLCKZ29F2DSNHkUTERcDF0taHBH7p46n\ngEbns4Da3u9dnN5hi4h4OHUcRTXp8vmpNDWf+XS5/wB8ISK+mzqe6UjalYaPopG0e0QsTx1HEW3I\nZz91vt+HvvhLmgvMB3YElgHr07ivAAAG0UlEQVSXRMSatFENJunzEfGnqeOYrC35zG+Y8RbgSOBF\nZHO9LEwb1dryUTQ/6LfcFJIOBN5Dz8RzTbuJC7Qqn28APgFsFBEvl/TRiKj1ZvNdGO3T6FEfko6a\n4utomtuR2uh8TsiH032dbMbMu4G1mqwaohWjaICzye6NO5es/2dZ2nD6aks+JzqmH8qXa++YHuY2\n/wlNH/XRto7UpucTAEmnAu8E/hP4AtkNvRut4aNoVkXEMkmrI2KJpNNSBzRIw/OZvGO6C8W/6aM+\n2taR2vR8TlgP+P2IWJk6kKm0cBTNI8puPL5c0hXAC1IH1KuF+UzeMd2FNv/fAT5Hdpu0VcDJEfGv\naaMarMEdqa3MZ1O1aBQNAJLmkM1A+Z2I+GnqeCZrUz5Td0x3ofi3YtRHizpSW5HPtmjLKJp8OofD\nI+LM1LFMp035TN0x3YUO312BW4CzJP2rpPmpA+qjFR2ptCefbbG1pKskXT/xlTqgPr4GrEgdRAFt\nyWfyjumhL/4tGvUxEhEfjohr8yFfv5U6oKm0KJ9t0ZZRNA8BX0kdRAFtyeevpeqYHvriL+lUScuB\njwBXAb+ZOKR+1kjaAaDJHaktymdbrIqIZcDqiFgC7JY6oD6WA9/sHZKcOqA+Gp1PScdJuh94jaT7\n8uc3Ap+tO5YujPZp9KiPHm2ZjqAt+WyLRo+i6fEkcDuwfb7c1M7CRuezSdNlDH2Hb1u4I7Xbmj6K\nph9JR0XEl1LHMVnT89mEjmkX/4Zoy3QEVq62jKLpR9L1TZrmoS35bMJ0GUPf5t8W7kjtrLaMoumn\nKbPOTmhLPpN3TLv4N4Q7UjurLaNo+mla00Fb8pm8Y7oLHb5t4Y7UbpoYRXPFxIomtqG3SFvymbxj\n2sW/ISLirNQxWBJtGUXTT9OafVqRz4h4G4CkU8g7puuOwR2+Zg3UtFE0+VnqHsDzJtZFxNJ0Ec1M\nA/OZvGPaxd+sgRo4iuafgSeAn+WrIiKOTRjSjDQwn/8OfCIiLksVg5t9zJqpac0pG0XEm1IHMQtN\ny2fyjmkXf7NmatpH8lsk/TGwZGJFRDyYMJ6Zalo+k3dMu/ibWRF75l8TTT0BNKYZpYWSd0y7+Js1\nU6OaKSJif0nrRcSvUseyjpqWzzOmWl9nx7Q7fM0SassoGkmfBN4YEY2aJXOytuSznzo7pn3mb5bW\nNUwaRQM0sViNNr3w59qSz35q+4Ti4m+WVltG0dwhaa+I+HbqQAZoSz77qa0pxsXfLK22jKLZBzhO\n0kqys9OIiB0SxzSVtuQzObf5myUkafGkVdGki5Hapu35rPMmLy7+Zom1YRSNpNdPXtfUjtSW5DN5\nx7SbfcwSmhhFQ8PuNTuFP+l5vivwCA3sSG1RPpN3TLv4m6XVilE0EfHr4i9pQ6Axk6RN0op80oCO\nad/MxSytOyTtlTqIQSRtO/EF/BawTeqY+mhFPsk7pifltVZu8zdLSNIy4OVAo0fR5B2pQRbjL4BF\nEfHNtFGtrWX57FV7x7SLv5lZAqk7pt3mb5ZQW0bRSDozIk7rt9wULcpn8o5pF3+ztFoxigaY3I7+\n2iRRDNaWfCbvmHbxN0uo6aNo8jPp/YF5kk7PV29OQ2tH0/PZI/l0GY38A5p1xaRRHs+jeaNoVgIr\ngKeAB/J1dwIfShXQdFqQzwnJp8tw8TdL6xKeO4rm02nDea6IuAe4R9IrI+KS1PEU0Oh8ToiIPVLH\n4NE+ZjaQpPWBPwS2iIjPStolIu5KHVdbNaFj2hd5mSUk6czplhvkS8AocHS+fF7CWPpqUT7/pOfr\nXOAv6w7AzT5mabVlFM02EfGunouTNkwaTX+tyGcTOqZd/M0SaNsoGmC1pFEgJO1Bw1oN2pbPJnRM\nNzIxZh3QqlE0wPHAOcDWwBnACWnDWUvb8pm8Y9odvmYJSfpURLwvdRxFpJ6OoIg25TO1Rn10M+ug\nD0g6QtK7ASTtkjqgqeTTESxPHUcBbcln8o5pF3+ztFoxioYGTEdQUFvymbxj2m3+Zmm1ZRRN8ukI\nCmp0PpvUMe3ib5ZWo0fR9Eg+HUFBTc9nYzqm3eFrlpCk7chG0bwCuAc4NSK+nzaq9mpLPpvQMe3i\nb5ZYG0bRtEkb8tmE6TKa9pHIrFNaNIqmFVqUz+Qd0y7+Zmm1ZRRNW7Qln9tExAeAx/Pl2jumXfzN\n0rpD0uRhf7bu2pLP5B3TbvM3S0jSMuDlZKNAmjyKphXaks8mdEy7+JuZJZC6Y9rNPmZmNWtCx7SL\nv5lZ/ZJ3TLv4m5nVL3nHtNv8zcxq1oSOaRd/M7MOcrOPmVkHufibmXWQi7+ZWQe5+JuZdZCLv5lZ\nB/03qRSh6TtlpyIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25ab6a94e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_new = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=30,\n",
    " max_depth=3,\n",
    " min_child_weight=46,\n",
    " gamma=5,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    "scale_pos_weight=1,\n",
    "seed=27)\n",
    "\n",
    "modelfit(xgb_new, train_final, predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGBClassifier??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lib = {'dtc': tree.DecisionTreeClassifier(min_samples_leaf=30), 'logreg': linear_model.LogisticRegression()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=46, missing=None, n_estimators=30,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_new.fit(train_final.iloc[:, :-1], train_final.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_new.predict(train_final.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=30, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc=model_lib['dtc']\n",
    "dtc.fit(train_final.iloc[:, :-1], train_final.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44229500989228404"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(dtc.predict(train_final.iloc[:, :-1]), train_final.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics.precision_score(dtc.predict(train_final.iloc[:, :-1]), train_final.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores_roc_dtc = cross_val_score(xgb_new, train_final.iloc[:, :-1], train_final.iloc[:, -1], cv=10, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42041854327420741"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_roc_dtc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10802850495921576"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_roc_dtc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(scores_roc_dtc.std(), scores_roc_log.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_final.iloc[:,:-1].copy(), train_final.iloc[:,-1].copy()\n",
    "X_test, y_test = test_final.iloc[:,:-1].copy(), test_final.iloc[:,-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树分类器的准确率：\n",
      " 0.500142218797\n",
      "决策树分类器run time(sec):\n",
      " 19.833750538181913\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "start = time.clock()\n",
    "dtc.fit(X_train, y_train)\n",
    "end = time.clock()\n",
    "dtc.score(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "print('决策树分类器的准确率：\\n', accuracy_score(y_test, y_pred))\n",
    "print('决策树分类器run time(sec):\\n', (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逻辑回归分类器的准确率：\n",
      " 0.526601796545\n",
      "逻辑回归分类器run time(sec):\n",
      " 5.572963362726323\n"
     ]
    }
   ],
   "source": [
    "Logreg = linear_model.LogisticRegression()\n",
    "start = time.clock()\n",
    "Logreg.fit(X_train, y_train)\n",
    "end = time.clock() \n",
    "y_pred = Logreg.predict(X_test)\n",
    "print('逻辑回归分类器的准确率：\\n', accuracy_score(y_test, y_pred))\n",
    "print('逻辑回归分类器run time(sec):\\n', (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=Logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48284796,  0.51715204],\n",
       "       [ 0.49266875,  0.50733125],\n",
       "       [ 0.5272896 ,  0.4727104 ],\n",
       "       ..., \n",
       "       [ 0.51859692,  0.48140308],\n",
       "       [ 0.49725712,  0.50274288],\n",
       "       [ 0.43092345,  0.56907655]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69801936469690118"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logreg.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = test_final.iloc[100,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2681024 ],\n",
       "       [-0.0585416 ],\n",
       "       [ 1.13307905],\n",
       "       [-0.68500126],\n",
       "       [ 0.01255389],\n",
       "       [-0.04142394],\n",
       "       [-0.03341019],\n",
       "       [ 0.0308386 ],\n",
       "       [-0.40017573],\n",
       "       [-0.05363267],\n",
       "       [ 0.0355111 ],\n",
       "       [-0.61993835],\n",
       "       [-0.07439054],\n",
       "       [-0.28385904],\n",
       "       [-0.2708666 ],\n",
       "       [-0.62928044],\n",
       "       [-0.11814996],\n",
       "       [ 0.5150603 ],\n",
       "       [-0.05608296],\n",
       "       [-0.52182836],\n",
       "       [-0.54028823],\n",
       "       [-0.70489831],\n",
       "       [-0.59599194],\n",
       "       [-0.41018654]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(new).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features per sample; expecting 24",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-258-b783a459f928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[0mcalculate_ovr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ovr\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcalculate_ovr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \"\"\"\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 305\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features per sample; expecting 24"
     ]
    }
   ],
   "source": [
    "Logreg.predict_proba(array(new).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\06_software\\Anoconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_class=xgb.XGBClassifier(\n",
    " learning_rate = 0.1,\n",
    " n_estimators = 1000,\n",
    " max_depth = 5,\n",
    " gamma = 0,\n",
    " subsample = 0.8,\n",
    " colsample_bytree = 0.8,\n",
    " objective = 'binary:logistic',\n",
    " nthread = 4,\n",
    " seed = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ab0f69ce9529>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_21\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mm_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy : %.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "m_class.fit(X_train, y_train)\n",
    "test_21=m_class.predict(X_test)\n",
    "print(\"Accuracy : %.2f\" % metrics.accuracy_score(y_test, test_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.49\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : %.2f\" % metrics.accuracy_score(y_test, test_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn import grid_search\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = { \\\n",
    "'max_depth': [i for i in range(3, 10, 2)], \\\n",
    "'min_child_weight': [i for i in range(1, 6, 2)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.29471, std: 0.13490, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.29492, std: 0.13480, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.29477, std: 0.13498, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.29265, std: 0.13457, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.29440, std: 0.13695, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.29623, std: 0.13994, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.28792, std: 0.13525, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.29011, std: 0.13929, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.28914, std: 0.13788, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.28457, std: 0.13466, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.28699, std: 0.13793, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: 0.28550, std: 0.13727, params: {'max_depth': 9, 'min_child_weight': 5}],\n",
       " {'max_depth': 5, 'min_child_weight': 5},\n",
       " 0.2962307059142266)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1 = grid_search.GridSearchCV( \\\n",
    "estimator = XGBClassifier(learning_rate=0.1,\n",
    "n_estimators=100, max_depth=5,\n",
    "min_child_weight=1,\n",
    "gamma=0,\n",
    "subsample=0.8,\n",
    "colsample_bytree=0.8,\n",
    "objective='binary:logistic',\n",
    "nthread=4,\n",
    "scale_pos_weight=1,\n",
    "seed=27),\n",
    "param_grid = param_test1,\n",
    "scoring = 'roc_auc',\n",
    "n_jobs = 4,\n",
    "iid = False,\n",
    "cv = 5)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2962307059142266"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b7f01cbb6b62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0miid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m cv = 5)\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mgsearch3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "param_test3={\n",
    " 'gamma': [i / 10.0 for i in range(0, 5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(\n",
    "estimator = XGBClassifier(\n",
    "learning_rate=0.1,\n",
    "n_estimators=140,\n",
    "max_depth=4,\n",
    "min_child_weight=6,\n",
    "gamma=0,\n",
    "subsample=0.8,\n",
    "colsample_bytree=0.8,\n",
    "objective='binary:logistic',\n",
    "nthread=4,\n",
    "scale_pos_weight=1,\n",
    "seed=27),\n",
    "param_grid = param_test3,\n",
    "scoring = 'roc_auc',\n",
    "n_jobs = 4,\n",
    "iid = False,\n",
    "cv = 5)\n",
    "gsearch3.fit(X_train, y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
